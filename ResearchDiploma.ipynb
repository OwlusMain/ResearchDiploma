{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "jw5yrauwkh9nvdvdaawvya",
    "id": "9zAJCYdpuf7m"
   },
   "source": [
    "# MoEBERT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1662,
   "metadata": {
    "cellId": "f29f3njbnpbaczax3m12u",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTt0ePKQiC6_",
    "outputId": "7ac7aa22-7980-4e14-c2af-b2ef92f9223b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.14.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /kernel/fallback/lib/python3.8/site-packages (from transformers) (1.19.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.50.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: requests in /kernel/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: six in /kernel/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.3)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2016,
   "metadata": {
    "cellId": "8ie7vekqy5axh8xuix0mm",
    "id": "bd8lt811bQE6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "#import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from keras_preprocessing import sequence\n",
    "#from keras_preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Layer, Input\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "from transformers.models.bert.modeling_tf_bert import TFBertLayer\n",
    "from transformers import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2017,
   "metadata": {
    "cellId": "mcitnj6qgbfjjjnzlm73sf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227,
     "referenced_widgets": [
      "48ccbe074b5147529d48bab43f8c8dab",
      "7adb9fbb59424545961a789656a27dbb",
      "a8536544f5db4500ad1df778e3cd0ff2",
      "3dacbbc126a34ec7b7e238b0f2042dee",
      "16214cc9a77149d4a6c64bdf16caed57",
      "d67b3a5e58d749f7b7fd55b712a49040",
      "318f38f2838b40919d288b57c4cc6445",
      "f05f44b87edc40fab3d7861374d7ca03",
      "ec86701ad9694d07abe9aeed38631f87",
      "14d1dc4ae1fb423a960e9717b84ca18e",
      "d71ffd8afea2405cafca5f074fbd5d1d",
      "5e53a9cafd2c48288f48a95e4733db5b",
      "fc829c95fbdd4007b8d11a3f610ab7cb",
      "af7499d604f74c0f9e538a43bef0e2e5",
      "c7e4462e4e2e4e879e7f31bad95147af",
      "437c94e6a03e4aa8b811be6b83d51bb0",
      "e37d0b0fcdc84112aa68b62d3689abf6",
      "20f456bc025c47d6968afcfea9321fac",
      "30db32156a864a28b310f2a358ae371c",
      "b7b0905822214873b6fda43797497329",
      "681d25c2f50d4f43a9c536bc9b1a6fbd",
      "a6dcbefcfe2d4847870c13ea1143ddf7",
      "4202a4ae12044b2a8217da9ed14d9bfe",
      "1a7d011ba7db4cecbcdb0e746dc21212",
      "58dac662548d480e8f0c338aba8fb641",
      "47f233df858049998d0116d58499d17a",
      "bd5b23b0773e4642a08de644618de002",
      "b390ab8ce5374817abaa209e1c2dbb08",
      "48ab82b2d1894c138664e9838cdd1e31",
      "be56b2fd335144499301187a095cbdf9",
      "0e612340791f46c784ee2cca4df8f6ed",
      "09ea9b71dcdc4ca681e86855e3ff159e",
      "8819d870656043649f2c52d87c9f5d31"
     ]
    },
    "id": "iewZzyc5iHzW",
    "outputId": "6eda58a1-3c8b-4b11-fa4b-a29a6ffdf9a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "encoder = TFBertModel.from_pretrained(\"model\", from_pt=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2018,
   "metadata": {
    "cellId": "l2ta2wcbe6dzfteviirpp",
    "id": "IPucHkyEFvx5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dropout, LayerNormalization, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "class BertLayer(Layer):\n",
    "    def __init__(self, num_heads, embeddings_dim, ff_dim, i):\n",
    "        super(BertLayer, self, ).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = embeddings_dim // num_heads\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=self.key_dim,  name=\"encoder_{}/multiheadattention\".format(i))\n",
    "        self.dp1 = Dropout(0.1, name=\"encoder_{}/att_dropout\".format(i))\n",
    "        self.ln1 = LayerNormalization(epsilon=1e-12, name=\"encoder_{}/att_layernormalization\".format(i))\n",
    "        self.ffn = Sequential([Dense(ff_dim, activation='gelu'),\n",
    "                               Dense(embeddings_dim),],\n",
    "                              name=\"encoder_{}/ffn\".format(i))\n",
    "        self.dp2 = Dropout(0.1, name=\"encoder_{}/ffn_dropout\".format(i))\n",
    "        self.ln2 = LayerNormalization(epsilon=1e-12, name=\"encoder_{}/ffn_layernormalization\".format(i))\n",
    "        \n",
    "\n",
    "    def call(self, query, key, value, attention_mask):\n",
    "        output1 = self.att(query, key, value, attention_mask=attention_mask)\n",
    "        output1 = self.dp1(output1)\n",
    "        output1 = self.ln1(query + output1)\n",
    "\n",
    "        output2 = self.ffn(output1)\n",
    "        output2 = self.dp2(output2)\n",
    "        result = self.ln2(output1 + output2)\n",
    "        return result\n",
    "\n",
    "    def set_pretrained(self, layer) :\n",
    "        att_ws = layer.attention.self_attention.weights + layer.attention.dense_output.dense.weights\n",
    "        for i in range(len(att_ws)) :\n",
    "            att_ws[i] = tf.reshape(att_ws[i], self.att.weights[i].shape)\n",
    "        self.att.set_weights(att_ws)\n",
    "        self.ln1.set_weights(layer.attention.dense_output.LayerNorm.weights)\n",
    "        self.ffn.layers[0].set_weights(layer.intermediate.weights)\n",
    "        self.ffn.layers[1].set_weights(layer.bert_output.dense.weights)\n",
    "        self.ln2.set_weights(layer.bert_output.LayerNorm.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2019,
   "metadata": {
    "cellId": "epjuntc63rqw2sat6nxe",
    "id": "iqSbwdSFyiH0"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from tensorflow.keras.layers import Add\n",
    "\n",
    "class SatLayer(Layer) :\n",
    "    def __init__(self, num_topics, num_heads, embeddings_dim, ff_dim):\n",
    "        super(SatLayer, self).__init__()\n",
    "        self.bertLayers = []\n",
    "        self.addLayer = Add()\n",
    "        self.num_topics = num_topics\n",
    "        for i in range(num_topics) :\n",
    "            self.bertLayers.append(BertLayer(num_heads, embeddings_dim, ff_dim, i + 12))\n",
    "\n",
    "    def call(self, inputs, attention_mask, ws):\n",
    "        outputs = []\n",
    "        \n",
    "        sat_res = ws\n",
    "        for i in range(self.num_topics) :\n",
    "            outputs.append(self.bertLayers[i](inputs, inputs, inputs, attention_mask) * tf.reshape(ws[:, i], (-1, 1, 1)))\n",
    "\n",
    "        return self.addLayer(outputs), sat_res\n",
    "\n",
    "    def set_pretrained(self, layer) :\n",
    "        #pass\n",
    "        self.bertLayers[0].set_pretrained(layer)\n",
    "        for curLayer in self.bertLayers :\n",
    "            curLayer.set_pretrained(layer)\n",
    "\n",
    "\n",
    "class TopicBertBase(Model):\n",
    "    def __init__(self, metaModel, num_topics, topic_pos, num_layers, num_heads, embeddings_dim, ff_dim, max_len, vocab_size, use_sat=True):\n",
    "        super(TopicBertBase, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.topic_pos = topic_pos\n",
    "        self.max_len = max_len\n",
    "        self.use_sat=use_sat\n",
    "\n",
    "        self.metaModel = metaModel\n",
    "\n",
    "        self.pos_emb = Embedding(max_len, embeddings_dim, name=\"position_embedding\", trainable=False)\n",
    "        self.word_emb = Embedding(vocab_size, embeddings_dim, name=\"word_embedding\", trainable=False)\n",
    "        self.seg_emb = Embedding(2, embeddings_dim, name=\"segment_embedding\", trainable=False)\n",
    "        self.dp = Dropout(0.1, name=\"encoder_emb_dropout\", trainable=False)\n",
    "        self.ln = LayerNormalization(epsilon=1e-12, name=\"encoder_emb_layernormalization\", trainable=False)\n",
    "        self.bertLayers = []\n",
    "        self.satLayer = SatLayer(num_topics, num_heads, embeddings_dim, ff_dim)\n",
    "        if self.use_sat == False :\n",
    "            for i in range(num_layers) :\n",
    "                self.bertLayers.append(BertLayer(num_heads, embeddings_dim, ff_dim, i))\n",
    "        else :\n",
    "            for i in range(num_layers - 1) :\n",
    "                self.bertLayers.append(BertLayer(num_heads, embeddings_dim, ff_dim, i))\n",
    "                self.bertLayers[-1].trainable = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.word_emb(inputs['input_ids']) + self.seg_emb(inputs['token_type_ids']) + self.pos_emb(tf.range(start=0, limit=self.max_len, delta=1))\n",
    "        outputs *= tf.expand_dims(inputs['attention_mask'], -1)\n",
    "        attention_mask = tf.matmul(tf.expand_dims(inputs['attention_mask'], -1), tf.expand_dims(inputs['attention_mask'], -2))\n",
    "\n",
    "        outputs = self.dp(outputs)\n",
    "        outputs = self.ln(outputs)\n",
    "        if self.use_sat == False :\n",
    "            for i in range(len(self.bertLayers)) :\n",
    "                  outputs = self.bertLayers[i](outputs, outputs, outputs, attention_mask)\n",
    "        else :\n",
    "            for i in range(self.topic_pos) :\n",
    "                outputs = self.bertLayers[i](outputs, outputs, outputs, attention_mask)\n",
    "\n",
    "            outputs, sat_res = self.satLayer(outputs, attention_mask, self.metaModel(inputs['meta_info']))\n",
    "\n",
    "            for i in range(self.topic_pos, self.num_layers - 1) :\n",
    "                outputs = self.bertLayers[i](outputs, outputs, outputs, attention_mask)\n",
    "\n",
    "        return outputs * tf.expand_dims(inputs['attention_mask'], -1), sat_res\n",
    "\n",
    "    def set_pretrained(self, model) :\n",
    "        self.pos_emb.set_weights([model.bert.embeddings.position_embeddings])\n",
    "        self.word_emb.set_weights([model.bert.embeddings.weight])\n",
    "        self.seg_emb.set_weights([model.bert.embeddings.token_type_embeddings])\n",
    "        self.ln.set_weights(model.bert.embeddings.LayerNorm.weights)\n",
    "        \n",
    "        if self.use_sat == False :\n",
    "            for i in range(len(self.bertLayers)) :\n",
    "                self.bertLayers[i].set_pretrained(model.bert.encoder.layer.layers[i])\n",
    "        else :\n",
    "            for i in range(self.topic_pos) :\n",
    "                self.bertLayers[i].set_pretrained(model.bert.encoder.layer.layers[i])\n",
    "\n",
    "            self.satLayer.set_pretrained(model.bert.encoder.layer.layers[self.topic_pos])\n",
    "\n",
    "            for i in range(self.topic_pos, self.num_layers - 1) :\n",
    "                self.bertLayers[i].set_pretrained(model.bert.encoder.layer.layers[i + 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2020,
   "metadata": {
    "cellId": "u7vw70g0aj921exzruyhmu",
    "id": "9HCjNqvmDH4p"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class GraphMoEBERT(Model):\n",
    "    def __init__(self, num_topics, topic_pos, num_layers, num_heads, embeddings_dim, ff_dim, max_len, vocab_size, use_sat=True):\n",
    "        super(GraphMoEBERT, self).__init__()\n",
    "        self.graphNN = Sequential()\n",
    "        self.graphNN.add(Dense(64, activation=\"gelu\"))\n",
    "        self.graphNN.add(Dense(num_topics, activation=\"softmax\"))\n",
    "        self.MoEBERT = TopicBertBase(self.graphNN, num_topics, topic_pos, num_layers, num_heads, embeddings_dim, ff_dim, max_len, vocab_size, use_sat)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.MoEBERT(inputs)\n",
    "\n",
    "    def set_pretrained(self, model) :\n",
    "        self.MoEBERT.set_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2021,
   "metadata": {
    "cellId": "sqxj7cw8x681awcb84rtjj",
    "id": "4piwa8Z6-JjD"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class MLModel(Model) :\n",
    "    def __init__(self, curModel, vocab_size, is_h=False):\n",
    "        super(MLModel, self).__init__()\n",
    "        self.curModel = curModel\n",
    "        self.is_h=is_h\n",
    "        #self.denseOutput = Sequential()\n",
    "        #self.denseOutput.add(Dense(256, activation='gelu'))\n",
    "        #self.denseOutput.add(LayerNormalization(epsilon=1e-12))\n",
    "        self.denseOutput = Dense(vocab_size, activation=\"softmax\")\n",
    "            \n",
    "        #self.di = Dense(768, activation=\"gelu\")\n",
    "\n",
    "        pad_val = np.zeros((1, 1, vocab_size))\n",
    "        pad_val[:, :, 0] = 1\n",
    "        self.pad_tensor = tf.constant(pad_val, dtype=tf.float32)\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = None\n",
    "        sat_res = None\n",
    "        if self.is_h :\n",
    "            outputs = self.denseOutput(self.curModel(inputs)['last_hidden_state'])\n",
    "        else :\n",
    "            outputs, sat_res = self.curModel(inputs)\n",
    "            outputs = self.denseOutput(outputs)\n",
    "        pads = tf.repeat(tf.repeat(self.pad_tensor, outputs.shape[1], 1), outputs.shape[0], 0)\n",
    "\n",
    "        outputs = outputs + pads * (1 - tf.expand_dims(inputs['attention_mask'], -1))\n",
    "        if self.is_h == True :\n",
    "            return outputs\n",
    "        \n",
    "        return outputs, sat_res\n",
    "\n",
    "    def train_step(self, data) :\n",
    "        x, y = data\n",
    "        sample_weights = x.pop(\"sample_weights\")\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss_sat = 0\n",
    "            batch_size = sample_weights.shape[0]\n",
    "            if self.is_h == False :\n",
    "              y_pred, sat_res = y_pred\n",
    "\n",
    "              for i in range(batch_size) :\n",
    "                  for j in range(i + 1, batch_size) :\n",
    "                      loss_sat += tf.reduce_sum(tf.math.abs(sat_res[i] - sat_res[j]))\n",
    "\n",
    "            \n",
    "            loss_mlm = self.compiled_loss(y, y_pred, sample_weight=sample_weights)\n",
    "            loss = tf.reduce_sum(loss_mlm) - loss_sat / 28\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        self.loss_tracker.update_state(loss_mlm, sample_weight=sample_weights)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {\"loss_mlm\": self.loss_tracker.result(), \"loss_sat\": loss_sat}\n",
    "\n",
    "    def predict(self, data) :\n",
    "        x = data\n",
    "\n",
    "        y_pred = self(x, training=False)\n",
    "        if self.is_h == False :\n",
    "            y_pred, sat_res = y_pred\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "\n",
    "    def set_pretrained(self, model) :\n",
    "        self.curModel.set_pretrained(model)\n",
    "\n",
    "    def set_trainable_stat(self, flag) :\n",
    "        self.curModel.trainable = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2022,
   "metadata": {
    "cellId": "5bu62hczo2izwhm88wmeeb"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class BinaryClassificationTaskModel(Model) :\n",
    "    def __init__(self, curModel, is_h=False):\n",
    "        super(BinaryClassificationTaskModel, self).__init__()\n",
    "        self.curModel = curModel\n",
    "        self.is_h=is_h\n",
    "        self.denseOutput = Sequential()\n",
    "        #self.denseOutput.add(Dropout(0.1))\n",
    "        self.denseOutput.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        outputs = None\n",
    "        if self.is_h :\n",
    "            outputs = self.curModel(inputs)['last_hidden_state'][:, 0, :]\n",
    "        else :\n",
    "            outputs, sat_res = self.curModel(inputs)\n",
    "            outputs = outputs[:, 0, :]\n",
    "        #outputs *= tf.expand_dims(inputs[\"attention_mask\"], -1)        \n",
    "        #outputs = tf.math.reduce_sum(outputs, 1) / tf.reduce_sum(inputs[\"attention_mask\"], -1, True)\n",
    "        outputs = self.denseOutput(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def set_pretrained(self, model) :\n",
    "        self.curModel.set_pretrained(model)\n",
    "\n",
    "    def set_trainable_stat(self, flag) :\n",
    "        self.curModel.trainable = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "i813siyhesiyj6sav4xxdr",
    "id": "fEne_AOaYLAj"
   },
   "outputs": [],
   "source": [
    "class ClassificationTaskModel(Model) :\n",
    "    def __init__(self, curModel, num_classes, is_h=False):\n",
    "        super(ClassificationTaskModel, self).__init__()\n",
    "        self.curModel = curModel\n",
    "        self.is_h=is_h\n",
    "        self.denseOutput = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        outputs = None\n",
    "        if self.is_h :\n",
    "            outputs = self.denseOutput(self.curModel(inputs)['last_hidden_state'][:, 0])\n",
    "        else :\n",
    "            outputs = self.denseOutput(self.curModel(inputs)[:, 0])\n",
    "        return outputs\n",
    "\n",
    "    def set_pretrained(self, model) :\n",
    "        self.curModel.set_pretrained(model)\n",
    "\n",
    "    def set_trainable_stat(self, flag) :\n",
    "        self.curModel.trainable = flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "42nbfvor98qg6y58dsagfr",
    "id": "y2M2ZOFYgtnT"
   },
   "outputs": [],
   "source": [
    "class GraphAttention(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        kernel_regularizer=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[0][-1], self.units),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.kernel_attention = self.add_weight(\n",
    "            shape=(self.units * 2, 1),\n",
    "            trainable=True,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            name=\"kernel_attention\",\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        node_states, edges = inputs\n",
    "\n",
    "        # Linearly transform node states\n",
    "        node_states_transformed = tf.matmul(node_states, self.kernel)\n",
    "\n",
    "        # (1) Compute pair-wise attention scores\n",
    "        node_states_expanded = tf.gather(node_states_transformed, edges)\n",
    "        node_states_expanded = tf.reshape(\n",
    "            node_states_expanded, (tf.shape(edges)[0], -1)\n",
    "        )\n",
    "        attention_scores = tf.nn.leaky_relu(\n",
    "            tf.matmul(node_states_expanded, self.kernel_attention)\n",
    "        )\n",
    "        attention_scores = tf.squeeze(attention_scores, -1)\n",
    "\n",
    "        # (2) Normalize attention scores\n",
    "        attention_scores = tf.math.exp(tf.clip_by_value(attention_scores, -2, 2))\n",
    "        attention_scores_sum = tf.math.unsorted_segment_sum(\n",
    "            data=attention_scores,\n",
    "            segment_ids=edges[:, 0],\n",
    "            num_segments=tf.reduce_max(edges[:, 0]) + 1,\n",
    "        )\n",
    "        attention_scores_sum = tf.repeat(\n",
    "            attention_scores_sum, tf.math.bincount(tf.cast(edges[:, 0], \"int32\"))\n",
    "        )\n",
    "        attention_scores_norm = attention_scores / attention_scores_sum\n",
    "\n",
    "        # (3) Gather node states of neighbors, apply attention scores and aggregate\n",
    "        node_states_neighbors = tf.gather(node_states_transformed, edges[:, 1])\n",
    "        out = tf.math.unsorted_segment_sum(\n",
    "            data=node_states_neighbors * attention_scores_norm[:, tf.newaxis],\n",
    "            segment_ids=edges[:, 0],\n",
    "            num_segments=tf.shape(node_states)[0],\n",
    "        )\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadGraphAttention(Layer):\n",
    "    def __init__(self, units, num_heads=8, merge_type=\"concat\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.merge_type = merge_type\n",
    "        self.attention_layers = [GraphAttention(units) for _ in range(num_heads)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        atom_features, pair_indices = inputs\n",
    "\n",
    "        # Obtain outputs from each attention head\n",
    "        outputs = [\n",
    "            attention_layer([atom_features, pair_indices])\n",
    "            for attention_layer in self.attention_layers\n",
    "        ]\n",
    "        # Concatenate or average the node states from each head\n",
    "        if self.merge_type == \"concat\":\n",
    "            outputs = tf.concat(outputs, axis=-1)\n",
    "        else:\n",
    "            outputs = tf.reduce_mean(tf.stack(outputs, axis=-1), axis=-1)\n",
    "        # Activate and return node states\n",
    "        return tf.nn.relu(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e65lpu2ooawvh4bgm6ggo",
    "id": "v_dOAa29guJI"
   },
   "outputs": [],
   "source": [
    "class GraphAttentionNetwork(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_features,\n",
    "        edges,\n",
    "        hidden_units,\n",
    "        num_heads,\n",
    "        num_layers,\n",
    "        output_dim,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.node_features = node_features\n",
    "        self.edges = edges\n",
    "        self.preprocess = Dense(hidden_units * num_heads, activation=\"relu\")\n",
    "        self.attention_layers = [\n",
    "            MultiHeadGraphAttention(hidden_units, num_heads) for _ in range(num_layers)\n",
    "        ]\n",
    "        self.output_layer = Dense(output_dim, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inds):\n",
    "        x = self.preprocess(self.node_features)\n",
    "        for attention_layer in self.attention_layers:\n",
    "            x = attention_layer([x, self.edges]) + x\n",
    "        new_fs = self.output_layer(x)\n",
    "        outputs = [new_fs[i:i + 1] for i in inds]\n",
    "        return tf.concat(outputs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "96mhn5jgfw5ki3scqwmnho",
    "id": "y5nLMQL0hxav"
   },
   "outputs": [],
   "source": [
    "class GATMoEBERT(Model):\n",
    "    def __init__(self, num_topics, topic_pos, num_layers, num_heads, embeddings_dim, ff_dim, max_len, vocab_size, node_features, edges, use_sat=True):\n",
    "        super(GATMoEBERT, self).__init__()\n",
    "        self.graphNN = Sequential\n",
    "        self.graphNN.add(GraphAttentionNetwork(node_features, edges, 100, 8, 3, num_topics))\n",
    "        self.graphNN.add(Dense(128, activation=\"gelu\"))\n",
    "        self.graphNN.add(Dense(num_topics, activation=\"softmax\"))\n",
    "        self.MoEBERT = TopicBertBase(self.graphNN, num_topics, topic_pos, num_layers, num_heads, embeddings_dim, ff_dim, max_len, vocab_size, use_sat)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.MoEBERT(inputs)\n",
    "\n",
    "    def set_pretrained(self, model) :\n",
    "        self.MoEBERT.set_pretrained(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "c4iqdnrvqdb4rzc1flxae",
    "id": "kPjphjScu-3v"
   },
   "source": [
    "# ArXiv data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "cellId": "g9yjeabgn2um647r88s7f",
    "id": "ejB6uNwDvFFa"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "cellId": "tjs60adnsnrgru3adqh9nu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4ewCt6PR9rL",
    "outputId": "fc9c6933-320c-4c09-811e-f32768a64b8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f3d4572d340>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/gdown/\u001b[0m\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%pip install gdown --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "cellId": "bvnhwf0dj8o0mtzt1tkhkz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvlWarka2mHz",
    "outputId": "67621287-ef09-4a94-c96c-7568878e0d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 10: gdown: not found\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Process exited with code 127",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ff65ad256a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdown https://drive.google.com/file/d/1BOi_w-5PWewCzZQdXxeBFKPrlTVB-D72/view?usp=sharing --fuzzy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_script_executor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScriptExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcessHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_script_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_message_handlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.8/site-packages/ml_kernel/script_executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, lang, code)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mreturn_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process exited with code %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreturn_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Process exited with code 127"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "!gdown https://drive.google.com/file/d/1BOi_w-5PWewCzZQdXxeBFKPrlTVB-D72/view?usp=sharing --fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "cellId": "uf3vanqetm5tgkylxcz5p"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "cellId": "ezjhmos229wdzzu9srzdfg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open the following url to obtain confirmation code: https://oauth.yandex.ru/authorize?response_type=code&client_id=0f1d4d16f51b4bc7a19cb0a2401358f3&display=popup&force_confirm=yes\n",
      "Enter the confirmation code:  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9a9f7b39e3d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 3. Paste into 'Callback URI': https://oauth.yandex.ru/verification_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 4. Set up permissions on yandex disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdisk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mya_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplication_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0f1d4d16f51b4bc7a19cb0a2401358f3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplication_secret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'81cf13ba65734c6da1ab16eb46abba19'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# downloading contents of the remote file into the local one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/cloud_ml/storage/api.py\u001b[0m in \u001b[0;36mya_disk\u001b[0;34m(application_id, application_secret, save_token, token_file_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0msave_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 token_file_path='/tmp/yadisk.token') -> Connector:\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mYaDisk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplication_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapplication_secret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/cloud_ml/storage/ya_disk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, application_id, application_secret, cache_token, token_file_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yadisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_code_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Open the following url to obtain confirmation code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the confirmation code: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yadisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             )\n\u001b[0;32m--> 857\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from cloud_ml.storage.api import Storage\n",
    "\n",
    "# To retrieve application id and secret:\n",
    "# 1. Go to link: https://oauth.yandex.ru/client/new\n",
    "# 2. Choose 'Web services'\n",
    "# 3. Paste into 'Callback URI': https://oauth.yandex.ru/verification_code\n",
    "# 4. Set up permissions on yandex disk\n",
    "disk = Storage.ya_disk(application_id='0f1d4d16f51b4bc7a19cb0a2401358f3', application_secret='81cf13ba65734c6da1ab16eb46abba19')\n",
    "\n",
    "# downloading contents of the remote file into the local one\n",
    "disk.get('path/to/file/within/ya/disk/file.txt', 'path/to/file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0y5v05dk4hecnoq5qilhu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFzoghm12j7R",
    "outputId": "386835b5-72f9-4bee-c10e-578ea0b4e148"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/file/d/15md54ItLBygX6knRyG04Kq0tct182Q0v/view?usp=sharing --fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "w0p4haqs27tuzumyni23",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIFJib3yX83t",
    "outputId": "76f17246-22ed-4712-f400-05d7c36596f9"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/file/d/1AJ-8Uiep6j54SQ__hBVd4fT0AqyOE5BH/view?usp=sharing --fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dp0bwvfvkli6fpc7h3ummi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QV13pImcpkpc",
    "outputId": "86e77c76-0eb4-4076-b116-65b0618731f6"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/file/d/1vIR3uXuIBnlyFDHFEKQnAlLQ9dY-MqXh/view?usp=sharing --fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "raiqaex4rzpqt0014qxupb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksAQ9lOGFJhQ",
    "outputId": "4e6c6357-2cd3-4816-c922-b949d1bfd129"
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1Vxn7HsQQ4s1Faby2J4sX1inUoEJXRdjt --fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "x73p88d0ege39epyjg3ur",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAwKAWufSuC8",
    "outputId": "eae37e05-852e-4d6a-b489-2f0ae7983838"
   },
   "outputs": [],
   "source": [
    "!unzip /content/archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "v2n8f6wy15rpulzb7yqmwe",
    "id": "b3ZhL080WWWC"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"arxiv-metadata-oai-snapshot.json\", \"r\") as f :\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "85sfi5h420vl0cfzoowz5",
    "id": "gS4SyvPxZexi"
   },
   "outputs": [],
   "source": [
    "data2 = data.split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "x9d9a37wzui9dzm3equhwm",
    "id": "z2dkZhJzx1od"
   },
   "outputs": [],
   "source": [
    "work = json.loads(data2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ddbor5rygfmwu79g5jzjg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Fg-g69Z-x8tu",
    "outputId": "d2255d6d-ec5a-48e0-a268-9f41a5d08933"
   },
   "outputs": [],
   "source": [
    "work[\"versions\"][0]['created'].split()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e10vrwueikla5vj5uxnvue",
    "id": "rOd7ZeV8oc5D"
   },
   "outputs": [],
   "source": [
    "cats = {}\n",
    "for i in range(len(data2)) :\n",
    "    work = json.loads(data2[i])\n",
    "    if int(work[\"versions\"][0]['created'].split()[3]) < 2001 :\n",
    "        continue\n",
    "    if work[\"categories\"] in cats :\n",
    "        cats[work[\"categories\"]].append(i)\n",
    "    else :\n",
    "        cats[work[\"categories\"]] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7010k8tr6mwr6udz7yusea",
    "id": "rEE59-SV0qFU"
   },
   "outputs": [],
   "source": [
    "szs = [len(x) for x in list(cats.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vgj7oyt6q8wscbbzpozs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_KfucN90tiZ",
    "outputId": "36359a99-a70e-4857-b19b-d8db75ad2433"
   },
   "outputs": [],
   "source": [
    "sorted(szs)[::-1][535]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1dkoppi8d3jgvuzg2zpcd6",
    "id": "VBhb9VKVqAPY"
   },
   "outputs": [],
   "source": [
    "relvs = []\n",
    "szs = []\n",
    "for key, value in cats.items() :\n",
    "    if len(value) >= 100 :\n",
    "        relvs.append(key)\n",
    "        szs.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xn9t9wzd4bqlshv41ho3t",
    "id": "d73Xea4w1dKf"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3gzpk98lbzdiygl773i72s",
    "id": "GFHhp_zFt_QZ"
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ceowhvyyhwp43qe3jw7n5l",
    "id": "-yoRNkHT1iLn"
   },
   "outputs": [],
   "source": [
    "relvsS = relvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "szn6tzn4ociddvmo7w8nl",
    "id": "AdMl1xKGuMpw"
   },
   "outputs": [],
   "source": [
    "G.add_nodes_from(range(len(relvsS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7pykzy6dpfhind76za9x5e",
    "id": "ynLFrO603rYw"
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ebb0t0tkrmnt8exkx3dz5a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzwHc55GTcPU",
    "outputId": "8d4d3086-dac1-41aa-fa6f-3bda13db1079"
   },
   "outputs": [],
   "source": [
    "subsS = []\n",
    "stoidx = dict()\n",
    "for i in tqdm.tqdm(relvsS) :\n",
    "    subsS.append(set())\n",
    "    for j in cats[i] :\n",
    "        work = json.loads(data2[j])\n",
    "        for author in work[\"authors_parsed\"] :\n",
    "            fullName = author[0] + \" \" + author[1] + \" \" + author[2]\n",
    "            if not (fullName in stoidx) :\n",
    "                stoidx[fullName] = len(stoidx)\n",
    "            subsS[-1].add(stoidx[fullName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9kp2u7bmnzgqtnq684qdm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KJJZtfBuRB8",
    "outputId": "9c9809c5-eb63-422e-84f6-34b6b07b8945"
   },
   "outputs": [],
   "source": [
    "adjMatr = np.zeros((len(relvsS), len(relvsS)))\n",
    "def count_jakkard(v, u, cats, data2) :\n",
    "    return float(len(subsS[v] & subsS[u])) / float(len(subsS[v] | subsS[u]))\n",
    "    \n",
    "\n",
    "    auth1 = set()\n",
    "    auth2 = set()\n",
    "    for i in cats[v] :\n",
    "        work = json.loads(data2[i])\n",
    "        for author in work[\"authors_parsed\"] :\n",
    "            auth1.add(author[0] + \" \" + author[1] + \" \" + author[2])\n",
    "    \n",
    "    for i in cats[u] :\n",
    "        work = json.loads(data2[i])\n",
    "        for author in work[\"authors_parsed\"] :\n",
    "            auth2.add(author[0] + \" \" + author[1] + \" \" + author[2])\n",
    "    \n",
    "    return float(len(auth1 & auth2)) / float(len(auth1 | auth2))\n",
    "\n",
    "for i in tqdm.tqdm(range(len(relvsS))) :\n",
    "    v = relvsS[i]\n",
    "    for j in range(i + 1, len(relvsS)) :\n",
    "        u = relvsS[j]\n",
    "        res = count_jakkard(i, j, cats, data2)\n",
    "        if res > 0.01 :\n",
    "            G.add_edge(i, j)\n",
    "        adjMatr[i][j] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1yix2yq91p4y54w43uwn38",
    "id": "zkI7fT6AVeBZ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "subrMatr = json.loads(open(\"subr_matr.json\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "4hwlfqxjrvf4dev30xqhbt",
    "id": "8qraG9YJVp_Q"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(len(subrMatr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "czm97bfugxiyqgss7czccb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "kQZWFSrgb5_R",
    "outputId": "29ae9f9c-0232-4a24-f178-893503d150a5"
   },
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "upo0o8y9zualqbavgx4j9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xwE6FN8V3Bo",
    "outputId": "87892e87-5af2-45b6-f2fe-5362c16dbba4"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "THRESHOLD = 0.01\n",
    "\n",
    "pbar = tqdm.tqdm(total=len(subrMatr)**2)\n",
    "for i in range(len(subrMatr)) :\n",
    "    for j in range(i + 1, len(subrMatr)) :\n",
    "        if float(subrMatr[i][j]) > 0.02 :\n",
    "            G.add_edge(i, j)\n",
    "        \n",
    "        pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "6tu81dut9frt12u3latn8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpBR_rdK561p",
    "outputId": "2fbfdeab-f0c8-4d78-ea48-9061da48e90f"
   },
   "outputs": [],
   "source": [
    "cnt = []\n",
    "for i in tqdm.tqdm(range(50)) :\n",
    "    THRESHOLD = 0.001 + 0.001 * i\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(len(subrMatr)))\n",
    "    for i in range(len(subrMatr)) :\n",
    "        for j in range(i + 1, len(subrMatr)) :\n",
    "            if float(subrMatr[i][j]) > THRESHOLD :\n",
    "                G.add_edge(i, j)\n",
    "    \n",
    "    cnt.append(nx.number_connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "iqooax92wdktehxr9onvnp",
    "id": "xZ9rwt97B4A_"
   },
   "outputs": [],
   "source": [
    "trsh = [0.001 + 0.001 * i for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e1lbhchynub41a1alko98",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "6uqahTATCC3x",
    "outputId": "937c8039-0056-437b-a084-68dcd49a9c66"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.plot(trsh, cnt)\n",
    "plt.ylabel(\"Components\")\n",
    "plt.xlabel(\"threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3nblu5uwjeny40gm4ss8xp",
    "id": "1fcrVqX67f5D"
   },
   "outputs": [],
   "source": [
    "nx.write_adjlist(G, path=\"graph.adjlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dwyv6qukynngcxffjqm7wf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlTi5gL9tJSn",
    "outputId": "f46e66d2-d148-4490-c06d-9e6bf35d6996"
   },
   "outputs": [],
   "source": [
    "len(subrMatr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "cv1c3fiirmcrpx1o1qirh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqWhGWugtCes",
    "outputId": "435d92fe-253d-4856-c476-4b2e09dbce2e"
   },
   "outputs": [],
   "source": [
    "len(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "75s3xunglk4u46zmghpgga",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xL7BczuT4bxi",
    "outputId": "41930b28-222c-4d92-ff9a-a13e0abe835b"
   },
   "outputs": [],
   "source": [
    "nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "bse8akm0kbmfhyvzen9bi9",
    "id": "rAcmLTk40I5C"
   },
   "outputs": [],
   "source": [
    "nx.write_graphml(G, \"graph2.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "b64ea6jwlfeihq51d85v9l",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFLFuF7AefOJ",
    "outputId": "9d1fc586-b9bb-4051-b1c2-28777f2d70f5"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/phanein/deepwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2gasfylamgf9f7z0hp6tpa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiqYhzVcj-xC",
    "outputId": "6329fa9e-6f41-4e1f-a6e2-dbef78353039"
   },
   "outputs": [],
   "source": [
    "!pip install -r /content/deepwalk/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k1uxc1gbxm7z2g3lgnl0ta",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCnedTgbkFsa",
    "outputId": "c7584fc2-faac-4b7d-e72a-958af58ff75a"
   },
   "outputs": [],
   "source": [
    "%cd deepwalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rqo3bm687vmxphgr1d8tqa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UrGD-0TolW4g",
    "outputId": "c9db8839-56e4-4aed-e154-559d52646ba6"
   },
   "outputs": [],
   "source": [
    "!python3 ./setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "134pfmc0whrhk720n0nitt",
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "GV3M2z5YkXpj",
    "outputId": "08a482fd-3893-4778-baca-395eb2530256"
   },
   "outputs": [],
   "source": [
    "!deepwalk --input ../graph.adjlist --number-walks 80 --walk-length 80 --window-size 10 --output ../reddit_0.02.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7x4apdlu7g4r4f1vkkiz",
    "id": "bPtE9iWq4Mhi"
   },
   "outputs": [],
   "source": [
    "embData = adjMatr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "95tn6jd9dajelejcpp94j",
    "id": "Xqg1vHN4_QwW"
   },
   "outputs": [],
   "source": [
    "embData = []\n",
    "with open(\"/content/reddit_0.02.embeddings\", \"r\") as f :\n",
    "    n, m = f.readline().split()\n",
    "    n = int(n)\n",
    "    m = int(m)\n",
    "    embData = np.zeros((n, m))\n",
    "    for i in range(n) :\n",
    "        nums = f.readline().split()\n",
    "        v = int(nums[0])\n",
    "        for j in range(m) :\n",
    "            embData[v][j] = float(nums[1 + j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "nt2d9un9upkgae0enchzeu",
    "id": "1n1iQ5nHd0Y0"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hgbxdo8mdqcip10hr3qwir",
    "id": "2AoYy47Y-jyA"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "6racdkia4hh064sayfc5j",
    "id": "6_YveUZ3_L6j"
   },
   "outputs": [],
   "source": [
    "def extract_arxiv_data(data2, relvsS, embData, cats) :\n",
    "    X = []\n",
    "    metaX = []\n",
    "    y = []\n",
    "    print(\"Extracting data\")\n",
    "    for i in tqdm.tqdm(range(len(relvsS))) :\n",
    "        for workInd in cats[relvsS[i]] :\n",
    "            work = json.loads(data2[workInd])\n",
    "            X.append(work[\"abstract\"])\n",
    "            metaX.append(embData[i])\n",
    "    \n",
    "    zipped = list(zip(X, metaX))\n",
    "    random.shuffle(zipped)\n",
    "    X, metaX = zip(*zipped)\n",
    "\n",
    "    return X, metaX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k7aqxz7gt4hem12g1vaelh",
    "id": "-9f9mK4RqLtI"
   },
   "outputs": [],
   "source": [
    "subrs = json.loads(open(\"proposed_subrs.json\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9jmfm8p20wppu72t60tabp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qL0zHpEqa38",
    "outputId": "fdbd8ea2-fc73-4faa-9a60-c2fb4445e4e6"
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"reddit_dump_tiny.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "a2fl4a8jpv8w6pxjtnfdwc",
    "id": "8kVAYMC2pQ1-"
   },
   "outputs": [],
   "source": [
    "def extract_reddit_data(data2, subrs, embData) :\n",
    "    subr_dict = dict()\n",
    "    for i in range(len(subrs)) :\n",
    "        subr_dict[subrs[i]] = i\n",
    "    print(\"Preprocessing reddit data\")\n",
    "    X = data2[\"body\"]\n",
    "    metaX = data2[\"subreddit_id\"].map(lambda x: embData[subr_dict[x]])\n",
    "\n",
    "    return X, metaX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "6j713nxhrjr1xkyv6ntcgp",
    "id": "H4dPDSUNAquN"
   },
   "outputs": [],
   "source": [
    "def prepare_arxiv_data(X, metaX, max_len=512) :\n",
    "    encoded_input = tokenizer(X, padding=True, pad_to_multiple_of=max_len, return_tensors=\"tf\", truncation=True, max_length=max_len)\n",
    "    encoded_input[\"attention_mask\"] = tf.cast(encoded_input[\"attention_mask\"], dtype=\"float32\")\n",
    "    encoded_input[\"input_ids\"] = encoded_input[\"input_ids\"].numpy()\n",
    "    encoded_input[\"meta_info\"] = np.zeros((len(X), len(metaX[0])))\n",
    "    y = []\n",
    "    y = np.zeros((len(X), max_len))\n",
    "    print(\"Post-processing\")\n",
    "    for i in tqdm.tqdm(range(len(X))) :\n",
    "        encoded_input[\"meta_info\"][i] = metaX[i]\n",
    "        y[i] = encoded_input[\"input_ids\"][i]\n",
    "    \n",
    "    return encoded_input, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xjhtznw4p6lvrekjs2ejpg",
    "id": "yaMUs1U1Fkmv"
   },
   "outputs": [],
   "source": [
    "def encode_input(input_str, meta_info = np.zeros((1, 64)), do_mask=True) :\n",
    "    encoded_input = tokenizer([input_str], padding=True, pad_to_multiple_of=512, return_tensors=\"tf\", truncation=True, max_length=512)\n",
    "    encoded_input[\"attention_mask\"] = tf.cast(encoded_input[\"attention_mask\"], dtype=\"float32\")\n",
    "    encoded_input[\"input_ids\"] = encoded_input[\"input_ids\"].numpy()\n",
    "    encoded_input[\"meta_info\"] = meta_info\n",
    "    if do_mask == True :\n",
    "        encoded_input[\"input_ids\"][:, int(tf.reduce_sum(encoded_input.attention_mask)) - 1:] = tokenizer.mask_token_id\n",
    "        encoded_input.attention_mask = tf.ones_like(encoded_input.attention_mask)\n",
    "\n",
    "    return encoded_input.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xvp9o7sepm935fgt4iiji9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPrr7TRm_nGe",
    "outputId": "8273e78a-bbe9-435a-9f72-bb240e5de61d"
   },
   "outputs": [],
   "source": [
    "Xdata, metaX = extract_arxiv_data(data2, relvsS, embData, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mtdha2wy99csahruxja3un",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PxTAcQgECq7G",
    "outputId": "cd22f310-7473-4958-9ebf-36408ca7a7bf"
   },
   "outputs": [],
   "source": [
    "l = 1000000\n",
    "r = 1000100\n",
    "X, y = prepare_arxiv_data(Xdata[l:r], metaX[l:r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "z4c515qm1hlmaekutqqwb",
    "id": "dV3W6P1Tjc6g"
   },
   "outputs": [],
   "source": [
    "l = 0\n",
    "r = 100000\n",
    "X_train = {}\n",
    "y_train = y[l:r]\n",
    "X_train[\"attention_mask\"] = X[\"attention_mask\"][l:r]\n",
    "X_train[\"input_ids\"] = X[\"input_ids\"][l:r]\n",
    "X_train[\"token_type_ids\"] = X[\"token_type_ids\"][l:r]\n",
    "X_train[\"meta_info\"] = X[\"meta_info\"][l:r]\n",
    "X_train[\"attention_mask\"] = tf.cast(X_train[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "bivmh8b9g34wxwo3n84xhg",
    "id": "3HKtEcJVkB51"
   },
   "outputs": [],
   "source": [
    "X_test = {}\n",
    "y_test = y[:]\n",
    "X_test[\"attention_mask\"] = tf.identity(X[\"attention_mask\"][:])\n",
    "X_test[\"input_ids\"] = tf.identity(X[\"input_ids\"][:])\n",
    "X_test[\"token_type_ids\"] = tf.identity(X[\"token_type_ids\"][:])\n",
    "X_test[\"meta_info\"] = tf.identity(X[\"meta_info\"][:])\n",
    "X_test[\"attention_mask\"] = tf.cast(X_test[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "unn8pfjy6iucyadp9roxp",
    "id": "hupMZDdCFviF"
   },
   "outputs": [],
   "source": [
    "X_test[\"input_ids\"] = X_test[\"input_ids\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "c71d84ghaq4icdqi1906b",
    "id": "LOVot8LpC4yi"
   },
   "outputs": [],
   "source": [
    "def mask_text(X, max_len=512) :\n",
    "    X[\"sample_weights\"] = np.zeros_like(X[\"input_ids\"])\n",
    "    for i in range(len(X[\"attention_mask\"])) :\n",
    "        inp_mask = (np.random.rand(max_len) < 0.15) & X[\"attention_mask\"][i].numpy().astype(bool)\n",
    "        X[\"sample_weights\"][i][inp_mask] = 1\n",
    "        ids = set(tokenizer.all_special_ids)\n",
    "        for j in range(max_len) :\n",
    "            if X[\"input_ids\"][i][j] in ids :\n",
    "                inp_mask[j] = False\n",
    "        inp_mask2 = inp_mask & (np.random.rand(max_len) < 0.80)\n",
    "        X[\"input_ids\"][i][inp_mask2] = tokenizer.mask_token_id\n",
    "        random_token_mask = inp_mask2 & (np.random.rand(max_len) < 1 / 10)\n",
    "\n",
    "        X[\"input_ids\"][i][random_token_mask] = np.random.randint(104, tokenizer.vocab_size, int(np.sum(random_token_mask)))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jbgouobmqj9ni9gqogffp",
    "id": "3r3bg0k_Fqt7"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "abxzd0pgnj7tdrufcop54n",
    "id": "P5Urxpk5NvFB"
   },
   "outputs": [],
   "source": [
    "X_train = mask_text(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kch7agwemvda72tf0t0vi",
    "id": "LwK_XbryguWx"
   },
   "outputs": [],
   "source": [
    "X_test_m = mask_text(copy.copy(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "malquo1bjqiw3u6jtdv2v",
    "id": "XBlWSYE7Qd03"
   },
   "outputs": [],
   "source": [
    "e_test = {}\n",
    "e_test[\"attention_mask\"] = X[\"attention_mask\"][0:1]\n",
    "e_test[\"input_ids\"] = X[\"input_ids\"][0:1]\n",
    "e_test[\"token_type_ids\"] = X[\"token_type_ids\"][0:1]\n",
    "e_test[\"meta_info\"] = X[\"meta_info\"][0:1]\n",
    "e_test[\"attention_mask\"] = tf.cast(e_test[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "j3qyas2to8r9ynw1ec6l",
    "id": "Jvv0GwkXwo8Q"
   },
   "outputs": [],
   "source": [
    "e_test2 = {}\n",
    "e_test2[\"attention_mask\"] = X[\"attention_mask\"][0:1]\n",
    "e_test2[\"input_ids\"] = X[\"input_ids\"][0:1]\n",
    "e_test2[\"token_type_ids\"] = X[\"token_type_ids\"][0:1]\n",
    "e_test2[\"attention_mask\"] = tf.cast(e_test2[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "z6meszekusg7ohqd88aqxd",
    "id": "1Ghah7c8Wiom"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {
    "cellId": "mtuo0e4g01dmvlhpu1g2h",
    "id": "bwdpniR2FJh6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GraphMoEBERT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7a93764ed1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGraphMoEBERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GraphMoEBERT' is not defined"
     ]
    }
   ],
   "source": [
    "model2 = MLModel(GraphMoEBERT(12, 2, 4, 4, 256, 256 * 4, 512, tokenizer.vocab_size), tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {
    "cellId": "f3ujfxm5ghirdgjvsz5wk",
    "id": "cgdiFndWXIQ3"
   },
   "outputs": [],
   "source": [
    "model = MLModel(encoder, tokenizer.vocab_size, is_h=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "refo6mqegmhdcvtsndda7e",
    "id": "5IgZ9JTRc708"
   },
   "outputs": [],
   "source": [
    "model3 = ClassificationTaskModel(model2.curModel, len(embData))\n",
    "model3.compile(tf.keras.optimizers.Adam(learning_rate=2e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "w2lw0mduafme6f1k0ilg",
    "id": "D_-FiS4CtPKP"
   },
   "outputs": [],
   "source": [
    "model.set_trainable_stat(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {
    "cellId": "pxmy9z32sftxcy74449tm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uXg0A4wZ5Sj",
    "outputId": "6e01a446-cb61-4b90-fd9c-e936f26a717d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 30522), dtype=float32, numpy=\n",
       "array([[[3.3546999e-05, 3.0846986e-05, 3.2323336e-05, ...,\n",
       "         3.5555688e-05, 3.9568637e-05, 3.1528245e-05],\n",
       "        [3.6782716e-05, 3.0768839e-05, 3.8683294e-05, ...,\n",
       "         3.7187947e-05, 3.1537496e-05, 3.1305201e-05],\n",
       "        [3.2484884e-05, 3.5742290e-05, 3.2092008e-05, ...,\n",
       "         3.9296880e-05, 3.1018637e-05, 2.9901610e-05],\n",
       "        ...,\n",
       "        [1.0000310e+00, 3.0645322e-05, 3.3079534e-05, ...,\n",
       "         3.5044017e-05, 3.7424950e-05, 2.9608618e-05],\n",
       "        [1.0000317e+00, 2.9540355e-05, 3.4866945e-05, ...,\n",
       "         3.7372785e-05, 3.5249239e-05, 2.8714383e-05],\n",
       "        [1.0000316e+00, 2.6373915e-05, 3.3662720e-05, ...,\n",
       "         3.7593363e-05, 4.3962958e-05, 3.2137945e-05]]], dtype=float32)>"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(e_test2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "b26c92hjvcgazpdz9am5s",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPTaPJS99Y6b",
    "outputId": "10cf6616-4bdb-4957-e7bf-49856e668097"
   },
   "outputs": [],
   "source": [
    "y_pred = model2.predict(e_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "r9gvsik9ihaxs0ulghl35",
    "id": "CPfKcSYfpyJP"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"bert_weights_arxiv_1550k.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "n0vob7sq01i29coyusy8l4",
    "id": "AaglTH4cFqYk"
   },
   "outputs": [],
   "source": [
    "model2.set_pretrained(model.curModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kr35v4o0d8oubri3nj96",
    "id": "7UqCsAS2K7Ji"
   },
   "outputs": [],
   "source": [
    "for i in range(len(model2.curModel.MoEBERT.bertLayers)) :\n",
    "    model2.curModel.MoEBERT.bertLayers[i].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3xx0w6mngcdd79rb06nixn",
    "id": "j667JeU0xH6n"
   },
   "outputs": [],
   "source": [
    "model2.denseOutput.set_weights(model.denseOutput.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "cellId": "e1f4m3jvtx7fp1i8qhwrv",
    "id": "OBs2BKKiasvc"
   },
   "outputs": [],
   "source": [
    "def perplexity(model, x, y) :\n",
    "    curLen = 0\n",
    "    ls = 0\n",
    "    for i in range(512) :\n",
    "        if y[0][i] == 102 :\n",
    "            curLen = i + 1\n",
    "            break\n",
    "\n",
    "    for k in tqdm.tqdm(range(1, curLen)) :\n",
    "        prev_id = x[\"input_ids\"][0][k]\n",
    "        x[\"input_ids\"][0][k] = 103\n",
    "        y_pred = model.predict(x)\n",
    "\n",
    "        curLoss = tf.keras.losses.sparse_categorical_crossentropy(y[0, k], y_pred[0, k])\n",
    "        ls+= curLoss\n",
    "        print(ls)\n",
    "\n",
    "        x[\"input_ids\"][0][k] = prev_id\n",
    "    return tf.exp(ls / (curLen - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e17sxip2ft03lnqe2e6z7y",
    "id": "-J8ik0vtHSFt"
   },
   "outputs": [],
   "source": [
    "model2.compile(tf.keras.optimizers.Adam(learning_rate=2e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "oc8aklf627ocn47o7ue5",
    "id": "DoiETtbzJ8VV"
   },
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "4ble263pv0leze3evxlki",
    "id": "8S7BKjv2wH1R"
   },
   "outputs": [],
   "source": [
    "model.set_trainable_stat(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "sqgmg290l4k6j3nk7hs1wx",
    "id": "tr290mKn78m9"
   },
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/MoEBERT_T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "oi8zmdp7mrc3nbkq6zq70m",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-s_2iDiZlKG",
    "outputId": "32773947-856a-4424-fafb-42b4f2f8b5af"
   },
   "outputs": [],
   "source": [
    "X_train_cls = copy.copy(X_train)\n",
    "X_train_cls.pop(\"sample_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2zsbvrttznmjgbqlb4ga8h",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTnxzsHUajVQ",
    "outputId": "05a98e51-5a6d-41b7-a74d-8fd10daeceb9"
   },
   "outputs": [],
   "source": [
    "y_train_cls = []\n",
    "for x in tqdm.tqdm(X_train_cls[\"meta_info\"]) :\n",
    "    for i in range(len(embData)) :\n",
    "        if np.all(embData[i] == x) :\n",
    "            y_train_cls.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xad6z5spdirbs0g8diumwj",
    "id": "IalBkvKad9NU"
   },
   "outputs": [],
   "source": [
    "y_train_cls = np.array(y_train_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "au29jzxb9iflmjm4k2kdg",
    "id": "ouSc0vewdYzZ"
   },
   "outputs": [],
   "source": [
    "y_train_cls_s = np.copy(y_train_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "r79rug8ku3ft0snix9xfz",
    "id": "bXgxagyyeYJU"
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "bnh6fns1qzfjp2z3kmxfoo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snwEpgoieP1p",
    "outputId": "eec63ac7-67c2-4e11-9f2d-81422215329a"
   },
   "outputs": [],
   "source": [
    "rng.shuffle(y_train_cls_s)\n",
    "for i in tqdm.tqdm(range(len(X_train_cls[\"meta_info\"]))) :\n",
    "    X_train_cls[\"meta_info\"][i] = embData[y_train_cls_s[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "41bmdh8z8rm2b0r1ypozg1",
    "id": "oASnHz4OS5O4"
   },
   "outputs": [],
   "source": [
    "model3.set_trainable_stat(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8383j7c6kdkd6qetluiihk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NgdsOMTddG_",
    "outputId": "90d6dfd8-ef95-4d61-b534-ae55891f8a70"
   },
   "outputs": [],
   "source": [
    "model3.fit(X_train_cls, y_train_cls_s, batch_size=8, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xvap73wtb99wx0df2r0f9",
    "id": "cIw25hIaJgQF"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"bert_weights_arxiv_1550k.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "j63dfzjzbeb0d6ewg5qcf",
    "id": "hUeSwdNjgBiS"
   },
   "outputs": [],
   "source": [
    "loss1 = []\n",
    "loss2 = []\n",
    "for i in tqdm.tqdm(range(2500, 3750)) :\n",
    "    e_test = {}\n",
    "    e_test[\"attention_mask\"] = X_train[\"attention_mask\"][i * 8:(i+1) * 8]\n",
    "    e_test[\"input_ids\"] = X_train[\"input_ids\"][i * 8:(i+1) * 8]\n",
    "    e_test[\"token_type_ids\"] = X_train[\"token_type_ids\"][i * 8:(i+1) * 8]\n",
    "    e_test[\"meta_info\"] = X_train[\"meta_info\"][i * 8:(i+1) * 8]\n",
    "    e_test[\"attention_mask\"] = tf.cast(e_test[\"attention_mask\"], dtype=\"float32\")\n",
    "    e_test[\"sample_weights\"] = X_train[\"sample_weights\"][i * 8:(i+1) * 8]\n",
    "    batch_y_train = y_train[i * 8:(i+1) * 8]\n",
    "\n",
    "    e_test_cls = copy.copy(e_test)\n",
    "    e_test_cls[\"meta_info\"] = X_train_cls[\"meta_info\"][i * 8:(i+1) * 8]\n",
    "    e_test_cls.pop(\"sample_weights\")\n",
    "\n",
    "    batch_y_train_cls = y_train_cls_s[i * 8:(i+1) * 8]\n",
    "\n",
    "    loss1.append(model2.train_on_batch(e_test, batch_y_train))\n",
    "    loss2.append(model3.train_on_batch(e_test_cls, batch_y_train_cls))\n",
    "\n",
    "    lb = min(32, len(loss1))\n",
    "\n",
    "    print(\"mlm loss:\", np.mean(loss1[-lb:]), \"cls loss:\", np.mean(loss2[-lb:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "f461ym64cafgiycivkmkl",
    "id": "3dIZHjY3ieER"
   },
   "outputs": [],
   "source": [
    "model2.curModel.set_weights(model3.curModel.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9hriftln2njwznf70p9lgc",
    "id": "OcDE5XVlqyC3"
   },
   "outputs": [],
   "source": [
    "model3.curModel.set_weights(model2.curModel.weights, steps_per_epoch=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9indn6arjcwmt8h8ckcgbn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uiisp257fSU3",
    "outputId": "2dea5958-37b6-4ba7-d959-e2e405b9f401"
   },
   "outputs": [],
   "source": [
    "model2.fit(X_train, y_train, batch_size=8, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "p60p0ozm17a9pi4qvdy1y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4mXkxrY1Wea",
    "outputId": "93c93792-c497-42ae-8721-b0ec641d1c3d"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "X_train_bert = copy.copy(X_train)\n",
    "X_train_bert.pop(\"meta_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "69f3vgeq6cj9r8yv68hm3c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5s1v6C2VhyG",
    "outputId": "316a0c07-31b8-4cc1-9702-f77960a5665b"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_bert, y_train, batch_size=8, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "cgxpgm25f6q5136clylps",
    "id": "6pDCNg1aQPIz"
   },
   "outputs": [],
   "source": [
    "model2.save_weights(\"moebert_weights_arxiv_1650k_v4.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0osdj75hkaht9ifqpbqtxk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72Q8ZvIt_11i",
    "outputId": "2b239a4b-55b0-425f-a392-79224285f1f7"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "X_test_bert = copy.copy(X_test_m)\n",
    "X_test_bert.pop(\"meta_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "l2nr7eg1j8ldyf0mlq20ol",
    "id": "cI96QcrRPeD-"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, x, y, sz) :\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    loss_mean = tf.keras.metrics.Mean()\n",
    "    loss = 0\n",
    "    for i in tqdm.tqdm(range(sz)) :\n",
    "        e_test = {}\n",
    "        e_test[\"attention_mask\"] = x[\"attention_mask\"][i:i+1]\n",
    "        e_test[\"input_ids\"] = x[\"input_ids\"][i:i+1]\n",
    "        e_test[\"token_type_ids\"] = x[\"token_type_ids\"][i:i+1]\n",
    "        if \"meta_info\" in x :\n",
    "            e_test[\"meta_info\"] = x[\"meta_info\"][i:i+1]\n",
    "        e_test[\"attention_mask\"] = tf.cast(e_test[\"attention_mask\"], dtype=\"float32\")\n",
    "\n",
    "        y_pred = model.predict(e_test)\n",
    "\n",
    "        curLoss = loss_mean(loss_fn(y[i:i+1], y_pred, sample_weight=x[\"sample_weights\"][i:i+1]), sample_weight=x[\"sample_weights\"][i:i+1])\n",
    "        loss += curLoss\n",
    "    \n",
    "    return loss / sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "eumdzvmzw4pm9krlqsx6tg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylwecpYdjbGx",
    "outputId": "1aa47d1f-07eb-4b4b-d008-9415813fd262"
   },
   "outputs": [],
   "source": [
    "evaluate_model(model2, X_test_m, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yr7kbvszqgbd4phe39i8v",
    "id": "vs4QT_JhBjKU"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "w689vbhomqml1no2e2q9",
    "id": "wyUbN4_tdMtE"
   },
   "outputs": [],
   "source": [
    "e_test = encode_input(\"this paper\", tf.expand_dims(embData[63], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "pl56unee81bbo1yntdfim",
    "id": "wKcnY53jr-bu"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "e_test = {}\n",
    "Xinp = X_train\n",
    "yinp = y_train\n",
    "e_test[\"attention_mask\"] = Xinp[\"attention_mask\"][i:i+1]\n",
    "e_test[\"input_ids\"] = Xinp[\"input_ids\"][i:i+1] #np.copy(yinp[i:i+1]).astype(np.int32)\n",
    "e_test[\"token_type_ids\"] = Xinp[\"token_type_ids\"][i:i+1]\n",
    "e_test[\"meta_info\"] = Xinp[\"meta_info\"][i:i+1]\n",
    "e_test[\"attention_mask\"] = tf.cast(e_test[\"attention_mask\"], dtype=\"float32\")\n",
    "e_test_y = yinp[i:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gc5h8evbjhigvm6n6lpas",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SwgaOXxIPuc",
    "outputId": "d64ffc18-a302-45b7-e47e-7f538493d9f8"
   },
   "outputs": [],
   "source": [
    "e_test2 = copy.copy(e_test)\n",
    "e_test2.pop(\"meta_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5s1h4migr3lzw134sqv4zg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iu_GoejLMsH",
    "outputId": "3b062ab9-bb50-4c80-eb10-a3797a6d2645"
   },
   "outputs": [],
   "source": [
    "metaInd = 1\n",
    "print(relvsS[metaInd])\n",
    "e_test[\"meta_info\"] = tf.expand_dims(embData[metaInd], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "en2bz2iybbhxe9dignpp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QL-_wSXrRJfj",
    "outputId": "a068ee73-e32c-4b4c-c10b-3af211a817a4"
   },
   "outputs": [],
   "source": [
    "model2(e_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "csfr3fhgzjiswhz17q5cs",
    "id": "nG26FExprIX9"
   },
   "outputs": [],
   "source": [
    "y_pred = model2.predict(e_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "o070b5tutib0gq0vn46epsf",
    "id": "2-BRbjpduKxH"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(e_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "d1mlgjrg6uux7r7t6zuajb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2thAR2cgtu4V",
    "outputId": "165dbb70-c6ef-43a9-fcf1-01ffb92c6b8c"
   },
   "outputs": [],
   "source": [
    "tf.keras.losses.SparseCategoricalCrossentropy()(e_test_y, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "uggotabhcev9vtx4pv70p",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pc101NjlBQnR",
    "outputId": "3ebc8078-b2d0-4b27-8634-08dd1210b929"
   },
   "outputs": [],
   "source": [
    "for i in range(100) :\n",
    "    e_test[\"meta_info\"] = tf.expand_dims(embData[i], 0)\n",
    "    print(tf.keras.losses.SparseCategoricalCrossentropy()(e_test_y, model2.predict(e_test)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xbbe22t2txjq7g0d7h48hj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0rL7QkhpiOd",
    "outputId": "05642213-dabe-43c8-8391-ecb0f5b2d7af"
   },
   "outputs": [],
   "source": [
    "perplexity(model2, e_test, e_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "wyhw30q9118s7rhhmizqr",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "CZcwUs7VgiFT",
    "outputId": "c5fa9c6d-6f5e-4b41-8cdc-1f1d1a61b1cf"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(np.squeeze(np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "x0ugiyb4fk9f4x01a9lni",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "jisXHp6NsKeo",
    "outputId": "fd0def1d-27ff-4f90-b427-f1baeb735d76"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(np.squeeze(np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "98zttr5jfhi4pmtekvp6g",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "O4SJg9TUsq_B",
    "outputId": "c5197aa7-4050-46b5-d7ee-6b43102ccc44"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(np.squeeze(e_test[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "40k77fqaw0prw5izuydx6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "3o4HWYPSs4n8",
    "outputId": "be79332d-d787-49ea-ad47-a3922980aa91"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(e_test_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "fcwgja9agkls6rlsh00zs",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "haSHxrUkkSX9",
    "outputId": "b11e7c60-4e5f-460f-aca9-972455aac44b"
   },
   "outputs": [],
   "source": [
    "\"We propose a new method in simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gb78huz8m8f1navmd9sthjj",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L28H6WeP-GUb",
    "outputId": "ee3fa38d-a90f-4178-ea2b-daa2b8006961"
   },
   "outputs": [],
   "source": [
    "for j in range(0, 100) :\n",
    "    curStr = \"We propose a new method in star\"\n",
    "    print(j, relvsS[j])\n",
    "    for i in range(7, 20) :\n",
    "        e_test = encode_input(curStr, tf.expand_dims(embData[j], 0))\n",
    "        y_pred = model2.predict(e_test)\n",
    "        curStr = tokenizer.decode(np.squeeze(np.argmax(y_pred, axis=-1))[1:i + 2])\n",
    "    print(curStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "g9fp5ol9thhlooa2xmqoj",
    "id": "iUdWcK1Nsbul"
   },
   "source": [
    "# Reddit processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2023,
   "metadata": {
    "cellId": "zkepecuvgedob61oy9ne7",
    "id": "-oZcRf7BslIJ"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "embData = []\n",
    "with open(\"reddit_0.02.embeddings\", \"r\") as f :\n",
    "    n, m = f.readline().split()\n",
    "    n = int(n)\n",
    "    m = int(m)\n",
    "    embData = np.zeros((n, m))\n",
    "    for i in range(n) :\n",
    "        nums = f.readline().split()\n",
    "        v = int(nums[0]) - 1\n",
    "        for j in range(m) :\n",
    "            embData[v][j] = float(nums[1 + j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2024,
   "metadata": {
    "cellId": "0bqo85ezgpn4151aldlo02",
    "id": "oCbMV8ysslIJ"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2025,
   "metadata": {
    "cellId": "c67jee2shojdlwpqw5wgx6",
    "id": "vY846xwVslIJ"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import random\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2026,
   "metadata": {
    "cellId": "0kj18vqq8wow3ytt6ybl1",
    "id": "c_Vuo5GdslIK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4412"
      ]
     },
     "execution_count": 2026,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "subrs = json.loads(open(\"proposed_subrs.json\", \"r\").read())[1:]\n",
    "len(subrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2027,
   "metadata": {
    "cellId": "padq71dfuogfderdpw2r5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7C8TQkgUslIK",
    "outputId": "ce1bc224-668a-43a4-fe4a-7eba7abb6940"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "data2 = pd.read_csv(\"2001/reddit_dump_tiny.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2028,
   "metadata": {
    "cellId": "4alkxkimloxxjvl40mf8k",
    "id": "quDf_7EvslIK"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def extract_reddit_data(data2, subrs, embData) :\n",
    "    subr_dict = dict()\n",
    "    for i in range(len(subrs)) :\n",
    "        subr_dict[subrs[i]] = i\n",
    "    print(\"Preprocessing reddit data\")\n",
    "    metaExists = data2[\"subreddit_id\"].map(lambda x: x in subr_dict).values\n",
    "    X = list(data2[\"body\"].iloc[metaExists].values)\n",
    "    metaX = data2[\"subreddit_id\"].iloc[metaExists].map(lambda x: embData[subr_dict[x]]).values\n",
    "\n",
    "    return X, metaX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2029,
   "metadata": {
    "cellId": "tibxnzv5oe2wmkdbxj541",
    "id": "0DHJNNTWslIK"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def prepare_data(X, metaX, max_len=512) :\n",
    "    encoded_input = tokenizer(X, padding=True, pad_to_multiple_of=max_len, return_tensors=\"tf\", truncation=True, max_length=max_len)\n",
    "    encoded_input[\"attention_mask\"] = tf.cast(encoded_input[\"attention_mask\"], dtype=\"float32\")\n",
    "    encoded_input[\"input_ids\"] = encoded_input[\"input_ids\"].numpy()\n",
    "    encoded_input[\"meta_info\"] = np.zeros((len(X), len(metaX[0])))\n",
    "    y = []\n",
    "    y = np.zeros((len(X), max_len))\n",
    "    print(\"Post-processing\")\n",
    "    for i in tqdm.tqdm(range(len(X))) :\n",
    "        encoded_input[\"meta_info\"][i] = metaX[i]\n",
    "        y[i] = encoded_input[\"input_ids\"][i]\n",
    "    \n",
    "    return encoded_input, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2030,
   "metadata": {
    "cellId": "glby9wgc3id5wta4tywv54",
    "id": "T0EXiNOQslIL"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def encode_input(input_str, meta_info = np.zeros((1, 64)), do_mask=True) :\n",
    "    encoded_input = tokenizer([input_str], padding=True, pad_to_multiple_of=512, return_tensors=\"tf\", truncation=True, max_length=512)\n",
    "    encoded_input[\"attention_mask\"] = tf.cast(encoded_input[\"attention_mask\"], dtype=\"float32\")\n",
    "    encoded_input[\"input_ids\"] = encoded_input[\"input_ids\"].numpy()\n",
    "    encoded_input[\"meta_info\"] = meta_info\n",
    "    if do_mask == True :\n",
    "        encoded_input[\"input_ids\"][:, int(tf.reduce_sum(encoded_input.attention_mask)) - 1:] = tokenizer.mask_token_id\n",
    "        encoded_input.attention_mask = tf.ones_like(encoded_input.attention_mask)\n",
    "\n",
    "    return encoded_input.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2031,
   "metadata": {
    "cellId": "q2d17l0uunwxk4gkd7q6d",
    "id": "yYLMEZb9wn8Z"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "data2 = data2[[\"body\", \"subreddit_id\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2032,
   "metadata": {
    "cellId": "o14kz5222bcb3m2qj7c49",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIhAwbrnslIL",
    "outputId": "568ed70e-68e9-4e6d-91bb-5f28c6d63e11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing reddit data\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "Xdata, metaX = extract_reddit_data(data2, subrs, embData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2033,
   "metadata": {
    "cellId": "womg43efakryw7bpa3i9z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQaEvRXg0bIb",
    "outputId": "bf2fe25a-9b88-480e-9cca-309b4ddc8559"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868710"
      ]
     },
     "execution_count": 2033,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "len(Xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2034,
   "metadata": {
    "cellId": "jkks0sc5wtb6h1r5nqjq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mqam4d5BslIL",
    "outputId": "801e814e-99ea-4ebc-adc3-bf06faa3399c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:00<00:00, 122892.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "l = 000000\n",
    "r = 100\n",
    "X, y = prepare_data(Xdata[l:r], metaX[l:r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2035,
   "metadata": {
    "cellId": "0slmr9sctjivijo4qnzf4o",
    "id": "QYX_5OISslIL"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "l = 0\n",
    "r = 100000\n",
    "X_train = {}\n",
    "y_train = y[l:r]\n",
    "X_train[\"attention_mask\"] = X[\"attention_mask\"][l:r]\n",
    "X_train[\"input_ids\"] = X[\"input_ids\"][l:r]\n",
    "X_train[\"token_type_ids\"] = X[\"token_type_ids\"][l:r]\n",
    "X_train[\"meta_info\"] = X[\"meta_info\"][l:r]\n",
    "X_train[\"attention_mask\"] = tf.cast(X_train[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1940,
   "metadata": {
    "cellId": "efw78vznu1t0lbrh4um69e",
    "id": "-H__MJsvslIL"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "X_test = {}\n",
    "y_test = y[:]\n",
    "X_test[\"attention_mask\"] = tf.identity(X[\"attention_mask\"][:])\n",
    "X_test[\"input_ids\"] = tf.identity(X[\"input_ids\"][:])\n",
    "X_test[\"token_type_ids\"] = tf.identity(X[\"token_type_ids\"][:])\n",
    "X_test[\"meta_info\"] = tf.identity(X[\"meta_info\"][:])\n",
    "X_test[\"attention_mask\"] = tf.cast(X_test[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1941,
   "metadata": {
    "cellId": "cqdenr2j0rkjbia0flqxg",
    "id": "saUIAtiAslIL"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "X_test[\"input_ids\"] = X_test[\"input_ids\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2036,
   "metadata": {
    "cellId": "fi6f94gm0athfw4buitiss",
    "id": "cOHrAOuTslIL"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def mask_text(X, max_len=512) :\n",
    "    X[\"sample_weights\"] = np.zeros_like(X[\"input_ids\"])\n",
    "    for i in range(len(X[\"attention_mask\"])) :\n",
    "        inp_mask = (np.random.rand(max_len) < 0.15) & X[\"attention_mask\"][i].numpy().astype(bool)\n",
    "        X[\"sample_weights\"][i][inp_mask] = 1\n",
    "        ids = set(tokenizer.all_special_ids)\n",
    "        for j in range(max_len) :\n",
    "            if X[\"input_ids\"][i][j] in ids :\n",
    "                inp_mask[j] = False\n",
    "        inp_mask2 = inp_mask & (np.random.rand(max_len) < 0.80)\n",
    "        X[\"input_ids\"][i][inp_mask2] = tokenizer.mask_token_id\n",
    "        random_token_mask = inp_mask2 & (np.random.rand(max_len) < 1 / 10)\n",
    "\n",
    "        X[\"input_ids\"][i][random_token_mask] = np.random.randint(104, tokenizer.vocab_size, int(np.sum(random_token_mask)))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2037,
   "metadata": {
    "cellId": "3rpgknmf41xjhbu4xb1fd",
    "id": "wCnH01I5slIM"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2006,
   "metadata": {
    "cellId": "lhjgb94637xdcm1p47z1q",
    "id": "V7b5WJ_OslIM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "X_train = mask_text(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1942,
   "metadata": {
    "cellId": "59kkd4z4n6pj9s8kpksqd",
    "id": "M3CnZne5slIM"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "X_test_m = mask_text(copy.copy(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2038,
   "metadata": {
    "cellId": "nsi36eunpi44wwipiqp1x",
    "id": "L77iY1AyslIM"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "e_test = {}\n",
    "e_test[\"attention_mask\"] = X[\"attention_mask\"][0:1]\n",
    "e_test[\"input_ids\"] = X[\"input_ids\"][0:1]\n",
    "e_test[\"token_type_ids\"] = X[\"token_type_ids\"][0:1]\n",
    "e_test[\"meta_info\"] = X[\"meta_info\"][0:1]\n",
    "e_test[\"attention_mask\"] = tf.cast(e_test[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2039,
   "metadata": {
    "cellId": "2s0abcouqr3cxqbu7vp1sg",
    "id": "0x_DJKe3slIM"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "e_test2 = {}\n",
    "e_test2[\"attention_mask\"] = X[\"attention_mask\"][0:1]\n",
    "e_test2[\"input_ids\"] = X[\"input_ids\"][0:1]\n",
    "e_test2[\"token_type_ids\"] = X[\"token_type_ids\"][0:1]\n",
    "e_test2[\"attention_mask\"] = tf.cast(e_test2[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2040,
   "metadata": {
    "cellId": "7ehnfm7eelsquplnqrax",
    "id": "rlacxYwmslIM"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2041,
   "metadata": {
    "cellId": "dewwtj8ude9192e7r5ltq",
    "id": "QLy3XeoYslIM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model2 = MLModel(GraphMoEBERT(4, 2, 4, 4, 256, 256 * 4, 512, tokenizer.vocab_size), tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2042,
   "metadata": {
    "cellId": "t3gf9dexcklij0nly67sd",
    "id": "qF9PrZDSslIM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model = MLModel(encoder, tokenizer.vocab_size, is_h=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5flx0e6pb1716fvdecrhux",
    "id": "ziW2n4ABslIN"
   },
   "outputs": [],
   "source": [
    "model.set_trainable_stat(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2043,
   "metadata": {
    "cellId": "js0lwh8k02r2wgytknnwap",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qr9xGnL4slIN",
    "outputId": "05c3d940-878e-44b7-c798-e01a949f38be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 30522), dtype=float32, numpy=\n",
       "array([[[3.4868066e-05, 3.3568816e-05, 3.4127141e-05, ...,\n",
       "         3.7567948e-05, 3.3197080e-05, 2.7782582e-05],\n",
       "        [3.6004571e-05, 3.2312168e-05, 2.9362760e-05, ...,\n",
       "         3.8603932e-05, 3.3711192e-05, 2.8358889e-05],\n",
       "        [3.4523102e-05, 3.3608780e-05, 3.3707955e-05, ...,\n",
       "         4.0261770e-05, 3.2801290e-05, 3.1159710e-05],\n",
       "        ...,\n",
       "        [1.0000329e+00, 3.5555397e-05, 3.1964504e-05, ...,\n",
       "         3.2998643e-05, 3.4561584e-05, 2.5751426e-05],\n",
       "        [1.0000328e+00, 3.5415105e-05, 3.1839867e-05, ...,\n",
       "         3.2620399e-05, 3.3585318e-05, 2.5916288e-05],\n",
       "        [1.0000348e+00, 3.3478045e-05, 3.2927779e-05, ...,\n",
       "         3.6631329e-05, 3.3802266e-05, 2.6661508e-05]]], dtype=float32)>"
      ]
     },
     "execution_count": 2043,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "y_pred = model(e_test2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2044,
   "metadata": {
    "cellId": "sv64ng26fjfa3f147nzzo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1njl3OkRslIN",
    "outputId": "ea4e9b72-a574-49ba-9cc8-839cbe8fbd74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 30522), dtype=float32, numpy=\n",
       "array([[[2.8291848e-05, 3.5563466e-05, 3.4831824e-05, ...,\n",
       "         3.7278267e-05, 3.6776040e-05, 2.6583304e-05],\n",
       "        [3.0053679e-05, 3.6438047e-05, 3.4744386e-05, ...,\n",
       "         3.4995610e-05, 3.1913602e-05, 3.3607728e-05],\n",
       "        [2.9408602e-05, 3.9903214e-05, 3.3586810e-05, ...,\n",
       "         3.8392103e-05, 3.3976168e-05, 3.1063104e-05],\n",
       "        ...,\n",
       "        [1.0000328e+00, 3.2763252e-05, 3.2763252e-05, ...,\n",
       "         3.2763252e-05, 3.2763252e-05, 3.2763252e-05],\n",
       "        [1.0000328e+00, 3.2763252e-05, 3.2763252e-05, ...,\n",
       "         3.2763252e-05, 3.2763252e-05, 3.2763252e-05],\n",
       "        [1.0000328e+00, 3.2763252e-05, 3.2763252e-05, ...,\n",
       "         3.2763252e-05, 3.2763252e-05, 3.2763252e-05]]], dtype=float32)>"
      ]
     },
     "execution_count": 2044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "y_pred = model2.predict(e_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2045,
   "metadata": {
    "cellId": "7wcj8uq3mxl5aaox8hb62f",
    "id": "bQYRIHmmslIN"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model.load_weights(\"bert_weights_reddit_3200k_v3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1946,
   "metadata": {
    "cellId": "td283iox0sj5wgfbq6u6q7",
    "id": "DEtb7bhfvqwk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model2.load_weights(\"moebert_2200k_4_topics.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "metadata": {
    "cellId": "q9r536lq1fjoql038fvh",
    "id": "YFv8B-KmEjXJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model.save_weights(\"bert_weights_reddit_3200k_v3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "cellId": "dzqavee7d2gkj3f5w44mm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qenz4gou1epoqaiounngp",
    "id": "RYmNgliTslIN"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model2.set_pretrained(model.curModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1893,
   "metadata": {
    "cellId": "p62ydjpsiqrobxqie3ra",
    "id": "Re4DqL1islIN"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for i in range(len(model2.curModel.MoEBERT.bertLayers)) :\n",
    "    model2.curModel.MoEBERT.bertLayers[i].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {
    "cellId": "yacu5lgm9gdo8nfnjycge"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model2.curModel.MoEBERT.bertLayers[-1].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "g6rkulay8uihuhxbbti4yp",
    "id": "ZeISifOVslIN"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model2.denseOutput.set_weights(model.denseOutput.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2046,
   "metadata": {
    "cellId": "bg6cynnoizv12u805gbhwg",
    "id": "sD9HiojCslIN"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def perplexity(model, x, y) :\n",
    "    curLen = 0\n",
    "    ls = 0\n",
    "    for i in range(512) :\n",
    "        if y[0][i] == 102 :\n",
    "            curLen = i + 1\n",
    "            break\n",
    "\n",
    "    for k in tqdm.tqdm(range(1, curLen)) :\n",
    "        prev_id = x[\"input_ids\"][0][k]\n",
    "        x[\"input_ids\"][0][k] = 103\n",
    "        y_pred = model.predict(x)\n",
    "\n",
    "        curLoss = tf.keras.losses.sparse_categorical_crossentropy(y[0, k], y_pred[0, k])\n",
    "        ls+= curLoss\n",
    "\n",
    "        x[\"input_ids\"][0][k] = prev_id\n",
    "    return tf.exp(ls / (curLen - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1894,
   "metadata": {
    "cellId": "vb3omgrhoa3fjixpq5cju",
    "id": "cITQ3QBtslIN"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model2.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2047,
   "metadata": {
    "cellId": "xsxvvov6jrsgad5mmwgxx",
    "id": "jGBnbNBjslIO"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss=tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xwej6s0o85gepefyz2mta",
    "id": "n7owBNArslIO"
   },
   "outputs": [],
   "source": [
    "model.set_trainable_stat(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ddkkhwk95cl0ee77k29zr",
    "id": "EbanU4iZslIO"
   },
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs/MoEBERT_T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1792,
   "metadata": {
    "cellId": "b4syusghd61zinddu10vli"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "rng = np.random.default_rng()\n",
    "rng.shuffle(X_train[\"meta_info\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {
    "cellId": "layorjqe0zlblbdnyp56bu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQVKnR7QslIP",
    "outputId": "f016590c-0958-4045-bb35-087be9d3ed6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1558s 125ms/step - loss_mlm: 2.8908 - loss_sat: 31.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff0eb318a30>"
      ]
     },
     "execution_count": 1924,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model, model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model2.fit(X_train, y_train, batch_size=8, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2012,
   "metadata": {
    "cellId": "0511peq3ej8ebfo5yd1i3vo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zS0qbunsslIP",
    "outputId": "e072d121-0d26-4544-cadd-78229a481ed6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.6652473e-03,  5.4641550e-03, -5.8550980e-03, ...,\n",
       "        -8.2636974e-04, -3.7490644e-03, -1.5158061e-03],\n",
       "       [-6.1945156e-03,  7.4199940e-03,  2.8067748e-03, ...,\n",
       "        -7.0403786e-03, -1.2712122e-03, -1.6435687e-03],\n",
       "       [-1.2236797e+00,  1.4707482e+00, -4.3001652e-01, ...,\n",
       "         8.7342850e-01, -1.0077835e+00,  6.6953330e-02],\n",
       "       ...,\n",
       "       [ 4.2996164e-03,  7.1728574e-03,  1.7592588e-03, ...,\n",
       "         8.0083957e-04,  1.2772186e-03, -2.3365791e-03],\n",
       "       [ 1.1990578e+00, -9.9521357e-01,  1.0145837e+00, ...,\n",
       "         2.0887601e-01,  1.0673581e-01,  7.8992110e-01],\n",
       "       [-3.6683101e-03,  6.6304870e-03, -8.8916125e-04, ...,\n",
       "        -1.8951952e-03,  4.6053124e-03,  5.7640290e-03]])"
      ]
     },
     "execution_count": 2012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import copy\n",
    "X_train_bert = copy.copy(X_train)\n",
    "X_train_bert.pop(\"meta_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2014,
   "metadata": {
    "cellId": "29obfsf9gaq5h4vu88lyz7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORvnl6rEslIQ",
    "outputId": "ed17ace8-8f6a-47e1-df16-73477a7e7092"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-33f5d49c20ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_bert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model.fit(X_train_bert, y_train, batch_size=8, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dkt50ghjnw9wauo84tlkgi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 21797/100000 [00:00<00:00, 217963.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:00<00:00, 222442.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for i in range(5):\n",
    "    l = 100000 * i\n",
    "    r = l + 100000\n",
    "    X, y = prepare_data(Xdata[l:r], metaX[l:r])\n",
    "    X_train = {}\n",
    "    y_train = y[:]\n",
    "    X_train[\"attention_mask\"] = X[\"attention_mask\"][:]\n",
    "    X_train[\"input_ids\"] = X[\"input_ids\"][:]\n",
    "    X_train[\"token_type_ids\"] = X[\"token_type_ids\"][:]\n",
    "    X_train[\"meta_info\"] = X[\"meta_info\"][:]\n",
    "    X_train[\"attention_mask\"] = tf.cast(X_train[\"attention_mask\"], dtype=\"float32\")\n",
    "    X_train = mask_text(X_train)\n",
    "    X_train_bert = copy.copy(X_train)\n",
    "    X_train_bert.pop(\"meta_info\")\n",
    "    \n",
    "    model.fit(X_train_bert, y_train, batch_size=8, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2003,
   "metadata": {
    "cellId": "13kztzri1nmhzlk2heae76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.41952"
      ]
     },
     "execution_count": 2003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "np.sum(X_train[\"attention_mask\"]) / 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {
    "cellId": "ffmrgd8h1pruprhfth2nke",
    "id": "Pc5rFgKbslIQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model, model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model2.save_weights(\"moebert_2200k_12_topics_new.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1949,
   "metadata": {
    "cellId": "jl0sljhtkwhshr2ail874h",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MluUIQsCslIQ",
    "outputId": "5ab22696-ddc2-42f4-862f-ee6bbe7b1962"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 64), dtype=float64, numpy=\n",
       "array([[-3.4292516e-01, -1.8143463e+00, -4.4616110e-01, ...,\n",
       "        -1.0859780e+00, -2.3399197e-01, -2.4376360e+00],\n",
       "       [-5.6006855e-01, -4.0428200e-01,  2.6992640e-01, ...,\n",
       "        -1.4965070e+00, -6.9368047e-01,  4.6438120e-01],\n",
       "       [-8.5244070e-02, -2.0868374e-01,  3.1962147e-01, ...,\n",
       "        -8.6283666e-01, -1.7619240e-01, -4.5285925e-01],\n",
       "       ...,\n",
       "       [-1.1718458e-04, -4.7975294e-03,  5.0611416e-04, ...,\n",
       "         6.3879870e-03,  8.3671673e-04,  2.8885321e-03],\n",
       "       [ 3.8091276e-02, -5.0505024e-01,  4.2351648e-01, ...,\n",
       "        -3.6511976e-01, -2.3805277e-02,  1.5277122e+00],\n",
       "       [ 9.3376076e-01,  9.8851970e-01,  4.5015827e-01, ...,\n",
       "         1.0953324e+00,  5.1993750e-01,  2.9502120e+00]])>"
      ]
     },
     "execution_count": 1949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import copy\n",
    "X_test_bert = copy.copy(X_test_m)\n",
    "X_test_bert.pop(\"meta_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "metadata": {
    "cellId": "eg6zm2l8cspecxbk9fjrkc",
    "id": "rBZVD0D9slIQ"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def evaluate_model(model, x, y, sz) :\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    loss_mean = tf.keras.metrics.Mean()\n",
    "    loss = 0\n",
    "    for i in tqdm.tqdm(range(sz)) :\n",
    "        e_test = {}\n",
    "        e_test[\"attention_mask\"] = x[\"attention_mask\"][i:i+1]\n",
    "        e_test[\"input_ids\"] = x[\"input_ids\"][i:i+1]\n",
    "        e_test[\"token_type_ids\"] = x[\"token_type_ids\"][i:i+1]\n",
    "        if \"meta_info\" in x :\n",
    "            e_test[\"meta_info\"] = x[\"meta_info\"][i:i+1]\n",
    "        e_test[\"attention_mask\"] = tf.cast(e_test[\"attention_mask\"], dtype=\"float32\")\n",
    "\n",
    "        y_pred = model.predict(e_test)\n",
    "\n",
    "        curLoss = loss_mean(loss_fn(y[i:i+1], y_pred, sample_weight=x[\"sample_weights\"][i:i+1]), sample_weight=x[\"sample_weights\"][i:i+1])\n",
    "        loss += curLoss\n",
    "    \n",
    "    return loss / sz\n",
    "\n",
    "def evaluate_perplexity(model, x, y, sz) :\n",
    "    ppl = 0\n",
    "    for i in tqdm.tqdm(range(sz)) :\n",
    "        e_test = {}\n",
    "        e_test[\"attention_mask\"] = x[\"attention_mask\"][i:i+1]\n",
    "        e_test[\"input_ids\"] = x[\"input_ids\"][i:i+1]\n",
    "        e_test[\"token_type_ids\"] = x[\"token_type_ids\"][i:i+1]\n",
    "        if \"meta_info\" in x :\n",
    "            e_test[\"meta_info\"] = x[\"meta_info\"][i:i+1]\n",
    "        e_test[\"attention_mask\"] = tf.cast(e_test[\"attention_mask\"], dtype=\"float32\")\n",
    "        if np.sum(e_test[\"attention_mask\"]) < 100 :\n",
    "            sz-=1\n",
    "            continue\n",
    "        ppl+=perplexity(model, e_test, y[i:i+1])\n",
    "    \n",
    "    return ppl / sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k6txbz7eruvyk3to3i95p"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "evaluate_perplexity(model2, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "w51d94sagla4r0haw8xpqa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2XssrsZslIQ",
    "outputId": "152d6eea-c826-4766-fe4f-43972212187b"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "evaluate_model(model, X_test_bert, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8lk5hiege3d8guhmna2okb",
    "id": "-4sa-3K6slIQ"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "cb0tna6hkr9skugf2u0gzm",
    "id": "mo3pox83slIQ"
   },
   "outputs": [],
   "source": [
    "e_test = encode_input(\"this paper\", tf.expand_dims(embData[63], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "metadata": {
    "cellId": "ogr7v4kg29ehkqxq5niuto",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "tIPnnQCYslIQ",
    "outputId": "c507cf4d-34fd-4561-bc83-ca340710e204"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] i agree, you have your personal responsibility to be prepared and to not get offended when you're legitimately called out. i am not here to hold your hand. read up on your class, the tactics. every instance has a guide. if you want story do storymode, in master mode with the increase in difficulty and added mechanics you're there with a different goal. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 1867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "i = 0\n",
    "e_test = {}\n",
    "Xinp = X_test\n",
    "yinp = y_test\n",
    "e_test[\"attention_mask\"] = Xinp[\"attention_mask\"][i:i+1]\n",
    "e_test[\"input_ids\"] = np.copy(yinp[i:i+1]).astype(np.int32)# Xinp[\"input_ids\"][i:i+1] #np.copy(yinp[i:i+1]).astype(np.int32)#\n",
    "e_test[\"token_type_ids\"] = Xinp[\"token_type_ids\"][i:i+1]\n",
    "e_test[\"meta_info\"] = Xinp[\"meta_info\"][i:i+1]\n",
    "e_test[\"attention_mask\"] = tf.cast(e_test[\"attention_mask\"], dtype=\"float32\")\n",
    "e_test_y = yinp[i:i+1]\n",
    "tokenizer.decode(np.squeeze(e_test[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "metadata": {
    "cellId": "0m8jo6kutiggjap7ngzn78g",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUP8eH8IslIR",
    "outputId": "8079c17c-b9bb-4d11-c23d-3d4186dd8b49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float64, numpy=\n",
       "array([[-0.00777813,  0.0071466 , -0.00050397, -0.00368676,  0.00344212,\n",
       "        -0.00148632, -0.0050067 ,  0.00142168,  0.00196621,  0.00148539,\n",
       "        -0.00403896, -0.00528146,  0.00213338,  0.00769987, -0.00671866,\n",
       "        -0.0046249 , -0.00664762,  0.00512588, -0.00221587, -0.00375469,\n",
       "         0.00751253, -0.00462278, -0.00084058,  0.00748602, -0.0015436 ,\n",
       "        -0.0015507 , -0.00686841, -0.00129243, -0.0068223 ,  0.00515729,\n",
       "        -0.00690322, -0.00274108,  0.00157256,  0.00236793, -0.00521422,\n",
       "        -0.00026875,  0.00722196, -0.00140778,  0.00504701, -0.00044573,\n",
       "        -0.0044426 , -0.00130919, -0.00593262, -0.00469751,  0.00041233,\n",
       "        -0.00359952,  0.00666726, -0.00623629, -0.00094124, -0.00418846,\n",
       "         0.00522944,  0.00684066,  0.00297584, -0.00105041,  0.00070968,\n",
       "         0.00535298,  0.00227766, -0.00506398,  0.0041305 ,  0.00460835,\n",
       "         0.0015106 ,  0.00425638,  0.00059343,  0.00622853]])>"
      ]
     },
     "execution_count": 1873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "e_test2 = copy.copy(e_test)\n",
    "e_test2.pop(\"meta_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {
    "cellId": "he3ls4j7mjokl436khx08",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pc9x12HdslIR",
    "outputId": "d45799f3-5452-4d96-ca69-8c64bce3b3fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5_10e2b7\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "metaInd = 4\n",
    "print(subrs[metaInd])\n",
    "e_test[\"meta_info\"] = tf.expand_dims(embData[metaInd], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "metadata": {
    "cellId": "8zd31bp2i12kqmvml229bl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-UyBJ9RslIR",
    "outputId": "95b77a8b-3f55-4289-c1a1-609e72c96920"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0.27748647, 0.29121837, 0.2512723 , 0.18002288]], dtype=float32)>"
      ]
     },
     "execution_count": 1868,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model2(e_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1869,
   "metadata": {
    "cellId": "y4o9v0m4winicc50ew3g9q",
    "id": "a-XjD9JJslIR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "y_pred = model2.predict(e_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1870,
   "metadata": {
    "cellId": "kskudks1zb82lzw7emrefu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69961023"
      ]
     },
     "execution_count": 1870,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "tf.keras.losses.SparseCategoricalCrossentropy()(e_test_y, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1874,
   "metadata": {
    "cellId": "vu0kh7vkeriepvuyd90vn",
    "id": "98H4wi6FslIR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "y_pred = model.predict(e_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "metadata": {
    "cellId": "jqx0z1frj7jmm3lg23pdps",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zPi0fIJslIR",
    "outputId": "5d63df36-a4c4-432d-c3de-9cd67b778d81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7121982"
      ]
     },
     "execution_count": 1875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "tf.keras.losses.SparseCategoricalCrossentropy()(e_test_y, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "p6zjozatyxnkws3gsbcqx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5s4LrfE5slIR",
    "outputId": "8dee18f4-bcce-4177-be5a-dbfba033a4d4"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for i in range(100) :\n",
    "    e_test[\"meta_info\"] = tf.expand_dims(embData[i], 0)\n",
    "    print(tf.keras.losses.SparseCategoricalCrossentropy()(e_test_y, model2.predict(e_test)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "u0amortgfkpelxtt6slm3d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Z4_yzlIslIS",
    "outputId": "616200b0-a9d0-402f-ec01-8fe2d2c79d6c"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "perplexity(model2, e_test, e_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8fl02aprwwp9iskw9lgs8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfBWSbhoryYK",
    "outputId": "22993d59-56c1-42b0-b063-754392463062"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "perplexity(model, e_test2, e_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "cellId": "vp0yzolhxognbajtnzxm0o",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "eWWT0-DtslIS",
    "outputId": "f75b7872-1d17-482b-8b93-86c27df13b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] holy shit, i had no idea. dooku played the conner in ww2. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "tokenizer.decode(np.squeeze(np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "h243ikoz2mictpg728dnb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "MakwfT-YslIS",
    "outputId": "f5cb0ad6-dbdb-4931-c248-9a09f0f6506c"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tokenizer.decode(np.squeeze(np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "u63e3bg41sh1608y9pfqql",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "-j4QkATxslIS",
    "outputId": "60c621ef-ea58-4bd0-881b-bd370ac1f008"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tokenizer.decode(np.squeeze(e_test[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jkzx6k2vnsgz8uuti43z2e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "FNFN9jSMslIS",
    "outputId": "c5391526-d58a-4602-e633-14897e2d4b96"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tokenizer.decode(e_test_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gtfv70od8s4cm8k4z80woh",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Ip8plJlbslIS",
    "outputId": "b11e7c60-4e5f-460f-aca9-972455aac44b"
   },
   "outputs": [],
   "source": [
    "\"We propose a new method in simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "metadata": {
    "cellId": "tenpvcwlwdkpp9pqplft7a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lGv2jUPZslIS",
    "outputId": "5aa83cb2-f48a-47e6-ab10-34113b2acac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 t5_2qh1i\n",
      "AskReddit\n",
      "white white white white white white white white white white\n",
      "1 t5_3j2jr\n",
      "CasualUK\n",
      "white white white white white white white white white white\n",
      "2 t5_2tycb\n",
      "OldSchoolCool\n",
      "white white white white white white white white white white\n",
      "3 t5_38qlm\n",
      "UberEATS\n",
      "white white white white white white white white white white\n",
      "4 t5_2qt55\n",
      "gifs\n",
      "white white white white white white white white white white\n",
      "5 t5_ac643\n",
      "FortniteCompetitive\n",
      "white white white white white white white white white white\n",
      "6 t5_2qmeb\n",
      "pokemon\n",
      "white white white white white white white white white white\n",
      "7 t5_2rluz\n",
      "hardstyle\n",
      "white white white white white white white white white white\n",
      "8 t5_2qjpg\n",
      "memes\n",
      "white white white white white white white white white white\n",
      "9 t5_2qh3v\n",
      "bestof\n",
      "white white white white white white white white white white\n",
      "10 t5_2qm9d\n",
      "CFB\n",
      "white white white white white white white white white white\n",
      "11 t5_2v08j\n",
      "NSFWIAMA\n",
      "white white white white white white white white white white\n",
      "12 t5_2sgp1\n",
      "pcmasterrace\n",
      "white white white white white white white white white white\n",
      "13 t5_2rjli\n",
      "teenagers\n",
      "white white white white white white white white white white\n",
      "14 t5_2qlqh\n",
      "Android\n",
      "white white white white white white white white white white\n",
      "15 t5_2qh13\n",
      "worldnews\n",
      "white white white white white white white white white white\n",
      "16 t5_2u3ta\n",
      "UpliftingNews\n",
      "white white white white white white white white white white\n",
      "17 t5_2qq5c\n",
      "gonewild\n",
      "white white white white white white white white white white\n",
      "18 t5_2qhc8\n",
      "guns\n",
      "white white white white white white white white white white\n",
      "19 t5_2qmg3\n",
      "nfl\n",
      "white white white white white white white white white white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model2\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for j in range(0, 20) :\n",
    "    curStr = \"\"\n",
    "    print(j, subrs[j])\n",
    "    if subrs[j] in matcher :\n",
    "        print(matcher[subrs[j]])\n",
    "    for i in range(1, 10) :\n",
    "        e_test = encode_input(curStr, tf.expand_dims(embData[j], 0))\n",
    "        y_pred = model2.predict(e_test)\n",
    "        curStr = tokenizer.decode(np.squeeze(np.argmax(y_pred, axis=-1))[1:i + 2])\n",
    "    print(curStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "q4coa67k919hj4lhhaxuy9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "g7lp6srggw815in48jkru"
   },
   "source": [
    "# Train SARC models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "cellId": "nwdpytxjskeew0q70e1r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%bzip2` not found.\n"
     ]
    },
    {
     "ename": "UsageError",
     "evalue": "Line magic function `%bzip2` not found.",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!g1.1\n",
    "%bzip2 -d comments.json.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {
    "cellId": "1w5a2w9pw3gjllzdr8gimp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import bz2\n",
    "sarcData = json.loads(bz2.open(\"comments.json.bz2\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {
    "cellId": "3ir0suitwhh5wm63q8min"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "matcher = json.loads(open(\"reddit_matcher.json\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {
    "cellId": "zxcp7yieb5rhxhtxc4whcg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "matcherr = dict(zip(matcher.values(), matcher.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {
    "cellId": "zinac7t8kws18ushw4b52mh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "lines = open(\"train-balanced.csv\", \"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {
    "cellId": "b54o85pbj8pc57wqvwkvqa"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "subr_dict = dict()\n",
    "for i in range(len(subrs)) :\n",
    "    subr_dict[subrs[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {
    "cellId": "jwoan4zl23671jqqvlq2f"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sarcX = []\n",
    "sarcMeta = []\n",
    "sarcY = []\n",
    "for line in lines :\n",
    "    _, comms, scores = line.split(sep='|')\n",
    "    comms = comms.split()\n",
    "    scores = scores.split()\n",
    "    for i in range(len(comms)) :\n",
    "        comm = sarcData[comms[i]]\n",
    "        if not (comm['subreddit'] in matcherr) :\n",
    "            continue\n",
    "        \n",
    "        sarcX.append(comm[\"text\"])\n",
    "        sarcMeta.append(embData[subr_dict[matcherr[comm[\"subreddit\"]]]])\n",
    "        sarcY.append(float(scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {
    "cellId": "5wwqe4xbg1dsathzqegoxk"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def prepare_sarc_data(X, metaX, max_len=512) :\n",
    "    encoded_input = tokenizer(X, padding=True, pad_to_multiple_of=max_len, return_tensors=\"tf\", truncation=True, max_length=max_len)\n",
    "    encoded_input[\"attention_mask\"] = tf.cast(encoded_input[\"attention_mask\"], dtype=\"float32\")\n",
    "    encoded_input[\"input_ids\"] = encoded_input[\"input_ids\"].numpy()\n",
    "    encoded_input[\"meta_info\"] = np.zeros((len(X), len(metaX[0])))\n",
    "    print(\"Post-processing\")\n",
    "    for i in tqdm.tqdm(range(len(X))) :\n",
    "        encoded_input[\"meta_info\"][i] = metaX[i]\n",
    "    \n",
    "    return encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1447,
   "metadata": {
    "cellId": "ipjjakejyamivy9gx6wrl"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "l = 100000\n",
    "r = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {
    "cellId": "6mcvv333rd9dcz6c6tazb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:00<00:00, 939460.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "sarcX_train_tmp = prepare_sarc_data(sarcX[l:r], sarcMeta[l:r])\n",
    "sarcY_train = np.array(sarcY[l:r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {
    "cellId": "vugybe1wmypm26h0r4jnp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [00:00<00:00, 609725.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "sarcX_test = prepare_sarc_data(sarcX[-1000:], sarcMeta[-1000:])\n",
    "sarcY_test = np.array(sarcY[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {
    "cellId": "7m5rb0gk5d6umd2h0gex"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "l = 0\n",
    "r = 1000\n",
    "sarcX_testt = {}\n",
    "sarcX_testt[\"attention_mask\"] = sarcX_test[\"attention_mask\"][l:r]\n",
    "sarcX_testt[\"input_ids\"] = sarcX_test[\"input_ids\"][l:r]\n",
    "sarcX_testt[\"token_type_ids\"] = sarcX_test[\"token_type_ids\"][l:r]\n",
    "sarcX_testt[\"meta_info\"] = sarcX_test[\"meta_info\"][l:r]\n",
    "sarcX_testt[\"attention_mask\"] = tf.cast(sarcX_testt[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "metadata": {
    "cellId": "3vroyoai03c7jbci4qzvr8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "l = 0\n",
    "r = 100000\n",
    "sarcX_train = {}\n",
    "sarcX_train[\"attention_mask\"] = sarcX_train_tmp[\"attention_mask\"][l:r]\n",
    "sarcX_train[\"input_ids\"] = sarcX_train_tmp[\"input_ids\"][l:r]\n",
    "sarcX_train[\"token_type_ids\"] = sarcX_train_tmp[\"token_type_ids\"][l:r]\n",
    "sarcX_train[\"meta_info\"] = sarcX_train_tmp[\"meta_info\"][l:r]\n",
    "sarcX_train[\"attention_mask\"] = tf.cast(sarcX_train[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "metadata": {
    "cellId": "z2eyd2trp3q2tjagk77az6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model5\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model5 = BinaryClassificationTaskModel(model2.curModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1435,
   "metadata": {
    "cellId": "s7690nut4xryuv4kb9cr0m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model5\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model5.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "metadata": {
    "cellId": "f8zfm1c01k7rg9bcrv0bbs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1428,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model5\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model5.curModel.MoEBERT.bertLayers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {
    "cellId": "dszxq5j1kpld9vrrtzfrd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model5\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for i in range(len(model5.curModel.MoEBERT.bertLayers)) :\n",
    "    model5.curModel.MoEBERT.bertLayers[i].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {
    "cellId": "ngo7fjk85fp5txfn33g9r8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1002s 80ms/step - loss: 0.6151 - accuracy: 0.6588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d64014850>"
      ]
     },
     "execution_count": 1451,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model5\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model5.fit(sarcX_train, sarcY_train, batch_size=8, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {
    "cellId": "dl9h40sr6l6ntnc0t987l"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9ab7588956a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msarcX_testt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msarcY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model5' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model5.evaluate(sarcX_testt, sarcY_test, batch_size=8, steps=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ihck83e2yinw4vt3lzbnsc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "l = 0\n",
    "r = 1000\n",
    "sarcX_testt = {}\n",
    "sarcX_testt[\"attention_mask\"] = sarcX_test[\"attention_mask\"][l:r]\n",
    "sarcX_testt[\"input_ids\"] = sarcX_test[\"input_ids\"][l:r]\n",
    "sarcX_testt[\"token_type_ids\"] = sarcX_test[\"token_type_ids\"][l:r]\n",
    "sarcX_testt[\"meta_info\"] = sarcX_test[\"meta_info\"][l:r]\n",
    "sarcX_testt[\"attention_mask\"] = tf.cast(sarcX_testt[\"attention_mask\"], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "cellId": "66oosel425q6kjtq8vwud"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model5\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "preds = model5.predict(sarcX_testt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {
    "cellId": "8fxshejsrobvwuzrgaawe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model5\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model5.save_weights(\"model5_weights_v3_3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {
    "cellId": "3mgpwycvqi3vjidl7t2vkn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/kernel.py:864: UserWarning: The following variables cannot be serialized: model5\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "model5.load_weights(\"model5_weights_v3_3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "eivewqyutfagtsyjsd3n9c"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model5.evaluate(sarcX_train, sarcY_train, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1gcw7n8ddkxh7acit3nw1dc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "kPjphjScu-3v"
   ],
   "machine_shape": "hm",
   "name": "  \"ResearchDiplomaDeepWalk.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "ff7d8104-936e-4f8f-82b5-ba6c48786d58",
  "notebookPath": "___ResearchDiplomaDeepWalk_ipynb_.ipynb",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09ea9b71dcdc4ca681e86855e3ff159e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e612340791f46c784ee2cca4df8f6ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "14d1dc4ae1fb423a960e9717b84ca18e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16214cc9a77149d4a6c64bdf16caed57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a7d011ba7db4cecbcdb0e746dc21212": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b390ab8ce5374817abaa209e1c2dbb08",
      "placeholder": "",
      "style": "IPY_MODEL_48ab82b2d1894c138664e9838cdd1e31",
      "value": "Downloading: 100%"
     }
    },
    "20f456bc025c47d6968afcfea9321fac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30db32156a864a28b310f2a358ae371c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "318f38f2838b40919d288b57c4cc6445": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dacbbc126a34ec7b7e238b0f2042dee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14d1dc4ae1fb423a960e9717b84ca18e",
      "placeholder": "",
      "style": "IPY_MODEL_d71ffd8afea2405cafca5f074fbd5d1d",
      "value": " 286/286 [00:00&lt;00:00, 10.3kB/s]"
     }
    },
    "4202a4ae12044b2a8217da9ed14d9bfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a7d011ba7db4cecbcdb0e746dc21212",
       "IPY_MODEL_58dac662548d480e8f0c338aba8fb641",
       "IPY_MODEL_47f233df858049998d0116d58499d17a"
      ],
      "layout": "IPY_MODEL_bd5b23b0773e4642a08de644618de002"
     }
    },
    "437c94e6a03e4aa8b811be6b83d51bb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47f233df858049998d0116d58499d17a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09ea9b71dcdc4ca681e86855e3ff159e",
      "placeholder": "",
      "style": "IPY_MODEL_8819d870656043649f2c52d87c9f5d31",
      "value": " 226k/226k [00:00&lt;00:00, 823kB/s]"
     }
    },
    "48ab82b2d1894c138664e9838cdd1e31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48ccbe074b5147529d48bab43f8c8dab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7adb9fbb59424545961a789656a27dbb",
       "IPY_MODEL_a8536544f5db4500ad1df778e3cd0ff2",
       "IPY_MODEL_3dacbbc126a34ec7b7e238b0f2042dee"
      ],
      "layout": "IPY_MODEL_16214cc9a77149d4a6c64bdf16caed57"
     }
    },
    "58dac662548d480e8f0c338aba8fb641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be56b2fd335144499301187a095cbdf9",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e612340791f46c784ee2cca4df8f6ed",
      "value": 231508
     }
    },
    "5e53a9cafd2c48288f48a95e4733db5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc829c95fbdd4007b8d11a3f610ab7cb",
       "IPY_MODEL_af7499d604f74c0f9e538a43bef0e2e5",
       "IPY_MODEL_c7e4462e4e2e4e879e7f31bad95147af"
      ],
      "layout": "IPY_MODEL_437c94e6a03e4aa8b811be6b83d51bb0"
     }
    },
    "681d25c2f50d4f43a9c536bc9b1a6fbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7adb9fbb59424545961a789656a27dbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d67b3a5e58d749f7b7fd55b712a49040",
      "placeholder": "",
      "style": "IPY_MODEL_318f38f2838b40919d288b57c4cc6445",
      "value": "Downloading: 100%"
     }
    },
    "8819d870656043649f2c52d87c9f5d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6dcbefcfe2d4847870c13ea1143ddf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8536544f5db4500ad1df778e3cd0ff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f05f44b87edc40fab3d7861374d7ca03",
      "max": 286,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec86701ad9694d07abe9aeed38631f87",
      "value": 286
     }
    },
    "af7499d604f74c0f9e538a43bef0e2e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30db32156a864a28b310f2a358ae371c",
      "max": 45106985,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b7b0905822214873b6fda43797497329",
      "value": 45106985
     }
    },
    "b390ab8ce5374817abaa209e1c2dbb08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7b0905822214873b6fda43797497329": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bd5b23b0773e4642a08de644618de002": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be56b2fd335144499301187a095cbdf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7e4462e4e2e4e879e7f31bad95147af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_681d25c2f50d4f43a9c536bc9b1a6fbd",
      "placeholder": "",
      "style": "IPY_MODEL_a6dcbefcfe2d4847870c13ea1143ddf7",
      "value": " 43.0M/43.0M [00:00&lt;00:00, 61.5MB/s]"
     }
    },
    "d67b3a5e58d749f7b7fd55b712a49040": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d71ffd8afea2405cafca5f074fbd5d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e37d0b0fcdc84112aa68b62d3689abf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec86701ad9694d07abe9aeed38631f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f05f44b87edc40fab3d7861374d7ca03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc829c95fbdd4007b8d11a3f610ab7cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e37d0b0fcdc84112aa68b62d3689abf6",
      "placeholder": "",
      "style": "IPY_MODEL_20f456bc025c47d6968afcfea9321fac",
      "value": "Downloading: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
